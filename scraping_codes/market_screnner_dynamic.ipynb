{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests-html in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.10.0)\n",
      "Requirement already satisfied: lxml[html_clean] in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.3.0)\n",
      "Requirement already satisfied: lxml-html-clean in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lxml[html_clean]) (0.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pyquery in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-html) (2.0.1)\n",
      "Requirement already satisfied: fake-useragent in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-html) (0.1.11)\n",
      "Requirement already satisfied: parse in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-html) (1.20.2)\n",
      "Requirement already satisfied: bs4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-html) (0.0.2)\n",
      "Requirement already satisfied: w3lib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-html) (2.2.1)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-html) (2.0.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests-html) (8.5.0)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n",
      "  Using cached pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests-html) (4.66.2)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests-html) (10.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyquery->requests-html) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.12.2)\n",
      "Using cached pyee-11.1.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pyee\n",
      "  Attempting uninstall: pyee\n",
      "    Found existing installation: pyee 12.0.0\n",
      "    Uninstalling pyee-12.0.0:\n",
      "      Successfully uninstalled pyee-12.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "playwright 1.47.0 requires pyee==12.0.0, but you have pyee 11.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyee-11.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'lxml[html_clean]' requests beautifulsoup4 pandas python-dotenv requests-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful!\n",
      "Scraping page 1: https://www.marketscreener.com/news/companies/recommandations/?p=1&cf=aVQwZTQzL1hkU0JOTloyNTNWTERkK0dzUlJtNWk0VjdHaHhrMk9LOXVSUkRpMXBLa3o2b0xhcHNzT3ZwdnF3VDhEbjhTelpKMlNMcitDNFNORE5aT2REL0NsZWlENytrK2EySElPUTh6U3R6MDhmdm10UkdPSUtmQldWTnhvVnY\n",
      "{'PHPSESSID': 'm5nlf691820pq30i3ng73mbbjg', 'zb_auth': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImFrSlhUVVkyYmtSTGVFeFlhMmRyYXpReVYwc3hRVDA5IiwiaWF0IjoxNzI5NTAzMjM2fQ.GGkyouWVWx-PS8YQnHgCi6dTfLYZ1fKFWs8N4DR1y4g', 'zb_membre': '1', 'pv_r0': '702', 'pv_r0_date': '2024-10-14', 'hmv': '028ca6183713b1f7a3b85584c8e7d0bf67d57634', 'pv_r0_rand': '10'}\n",
      "Skipping page https://www.marketscreener.com/quote/stock/FASTENAL-COMPANY-4901/news/Fastenal-Company-Reports-Earnings-Results-for-the-Third-Quarter-and-Nine-Months-Ended-September-30-48059209/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/ENNIS-INC-12395/news/Detachement-de-48009410/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/UBER-TECHNOLOGIES-INC-57860975/news/Uber-Lyft-Shares-Rise-10-After-Tesla-s-Robotaxi-Event-48061001/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/TESLA-INC-6344549/news/Tesla-s-Musk-to-unveil-robotaxis-amid-fanfare-and-skepticism-48047159/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/BANK7-CORP-46276392/news/Bank7-Corp-Reports-Earnings-Results-for-the-Third-Quarter-and-Nine-Months-Ended-September-30-2024-48059808/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/WELLS-FARGO-COMPANY-14861/news/Markets-turn-cautious-before-uncertain-weekend-48048117/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/A-O-SMITH-CORPORATION-40311155/news/A-O-Smith-Corporation-Revises-Earnings-Guidance-for-the-Full-Year-2024-48061225/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/NURIX-THERAPEUTICS-INC-110038769/news/Nurix-Therapeutics-Inc-Reports-Earnings-Results-for-the-Third-Quarter-and-Nine-Months-Ended-August-48062401/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/COHERENT-CORP-9656/news/Coherent-Corp-Appoints-Sherri-R-Luther-as-Treasurer-48061135/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/JPMORGAN-CHASE-CO-37468997/news/Russian-court-orders-seizure-of-155-8-million-in-JPMorgan-Chase-funds-in-VTB-lawsuit-48058340/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/UGI-CORPORATION-14738/news/UGI-Corporation-Enters-into-Certain-Credit-Agreement-48064463/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/PERSPECTIVE-THERAPEUTICS--15515/news/Perspective-Therapeutics-to-Advance-Investigation-of-Potential-First-In-Class-Radiopharmaceutical-Th-48059797/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/MOOG-INC-13587/news/Moog-Fined-1-1-Million-by-SEC-for-Bribery-Charges-48060225/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/EXCELERATE-ENERGY-INC-136211574/news/Excelerate-Energy-Inc-Announces-Changes-to-Board-of-Directors-and-Committees-48062423/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/MDU-RESOURCES-GROUP-INC-13482/news/MDU-Resources-Group-Inc-NYSE-MDU-added-to-S-P-600-Industrials-48047370/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/CSW-INDUSTRIALS-INC-23733723/news/CSW-Industrials-Inc-Declares-Quarterly-Dividend-Payable-on-November-8-2024-48059449/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/GIBRALTAR-INDUSTRIES-INC-10695/news/Gibraltar-Industries-Inc-Revises-Consolidated-Earnings-Guidance-for-the-Full-Year-Ending-December-48059318/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/ACRIVON-THERAPEUTICS-INC-146590781/news/Acrivon-Therapeutics-Inc-Announces-Initial-Patient-Dosing-in-Phase-1-Trial-of-ACR-2316-a-Novel-WE-48059810/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/HUNTINGTON-INGALLS-INDUST-7642101/news/North-American-Morning-Briefing-Caution-Seen-as-2-48058372/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/BANK-OZK-44965059/news/Detachement-de-48064099/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/ROYALTY-PHARMA-PLC-108435084/news/Royalty-Pharma-Declares-Fourth-Quarter-2024-Dividend-Payable-on-December-10-2024-48059451/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/MARVELL-TECHNOLOGY-GROUP--4934/news/Detachement-de-47959076/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/PENNYMAC-MORTGAGE-INVESTM-5481942/news/Detachement-de-47959091/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/AMERICA-S-CAR-MART-INC-8902/news/America-s-Car-Mart-Inc-Completes-300-Million-Term-Securitization-48061276/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/IDEX-CORPORATION-13044/news/Detachement-de-47959067/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/BOEING-4816/news/Boeing-files-unfair-labor-practice-charge-against-striking-union-48047816/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/APPIAN-CORPORATION-34991348/news/Appian-Appoints-Mark-Dorsey-as-Chief-Revenue-Officer-48061139/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/MORGAN-STANLEY-13654/news/Bank-of-Korea-Cuts-Interest-Rate-to-3-25-as-Expected-48060656/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/ARITZIA-INC-31497418/news/Toronto-Stocks-Advance-Aritzia-Shares-Fall-on-Moderated-3Q-Full-Year-Outlook-48061074/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/G-MINING-VENTURES-CORP-173011287/news/G-Mining-Ventures-Corp-Announces-Board-Changes-48059635/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/GOLDMINING-INC-7982445/news/GoldMining-Inc-Reports-Earnings-Results-for-the-Third-Quarter-and-Nine-Months-Ended-August-31-2024-48062429/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/G2-GOLDFIELDS-INC-64307960/news/G2-Goldfields-Inc-Reports-Earnings-Results-for-the-First-Quarter-Ended-August-31-2024-48059455/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/CELESTICA-INC-1409491/news/Celestica-Inc-Launches-the-DS4100-its-Latest-800G-Switch-Optimized-for-AI-ML-Data-Center-Workloads-48059628/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/MTY-FOOD-GROUP-INC-1410921/news/MTY-Food-Group-Inc-Declares-Quarterly-Dividend-Payable-on-November-15-2024-48059204/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/EQUINOX-GOLD-CORP-45205597/news/Equinox-Gold-Corp-Announces-the-Resignation-of-Fraz-Siddiqui-as-Board-of-Director-48048015/: Published in September 2024\n",
      "Skipping page https://www.marketscreener.com/quote/stock/NEXTSOURCE-MATERIALS-INC-42378635/news/NextSource-Materials-Inc-announced-that-it-has-received-CAD-14-695893-million-in-funding-from-Visio-48066173/: Published in September 2024\n",
      "Scraped: QIAGEN NV  :  DZ Bank keeps its Buy rating\n",
      "Scraped: PFIZER INC  :  UBS remains Neutral\n",
      "Scraped: PFIZER INC  :  JP Morgan sticks Neutral\n",
      "Scraped: MICROSOFT CORP  :  Jefferies reaffirms its Buy rating\n",
      "Scraped: MOSAIC  :  Berenberg remains Neutral\n",
      "Scraped: QIAGEN NV  :  Deutsche Bank gives a Buy rating\n",
      "Scraped: BOEING CO  :  Gets a Neutral rating from RBC\n",
      "Scraped: JPMORGAN  :  Credit Suisse gives a Buy rating\n",
      "Scraped: BOEING CO  :  JP Morgan keeps its Buy rating\n",
      "Scraped: MOSAIC  :  JP Morgan remains its Buy rating\n",
      "Scraped: SALESFORCE  :  Goldman Sachs maintains a Buy rating\n",
      "Scraped: INTEL CORP  :  Credit Suisse sticks Neutral\n",
      "Scraped: LINDE PLC  :  Jefferies gives a Buy rating\n",
      "Scraped: INTEL CORP  :  Gets a Sell rating from JP Morgan\n",
      "Scraped: TESLA  :  Bernstein reiterates its Sell rating\n",
      "Scraped: WALMART  :  UBS reiterates its Buy rating\n",
      "Scraped: UNITED PARCEL SERVICE INC  :  Credit Suisse reiterates its Buy rating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-41865' coro=<Connection._async_send() done, defined at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyppeteer/connection.py:69> exception=RuntimeError('This event loop is already running')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyppeteer/connection.py\", line 73, in _async_send\n",
      "    await self.connection.send(msg)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/websockets/legacy/protocol.py\", line 647, in send\n",
      "    await self.write_frame(True, opcode, data)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/websockets/legacy/protocol.py\", line 1213, in write_frame\n",
      "    self.write_frame_sync(fin, opcode, data)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/websockets/legacy/protocol.py\", line 1184, in write_frame_sync\n",
      "    frame.write(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/websockets/legacy/framing.py\", line 145, in write\n",
      "    write(self.new_frame.serialize(mask=mask, extensions=extensions))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/websockets/frames.py\", line 271, in serialize\n",
      "    self = extension.encode(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/websockets/extensions/permessage_deflate.py\", line 163, in encode\n",
      "    data = self.encoder.compress(frame.data) + self.encoder.flush(zlib.Z_SYNC_FLUSH)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyppeteer/launcher.py\", line 153, in _close_process\n",
      "    self._loop.run_until_complete(self.killChrome())\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 629, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 588, in _check_running\n",
      "    raise RuntimeError('This event loop is already running')\n",
      "RuntimeError: This event loop is already running\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:1923: RuntimeWarning: coroutine 'Launcher.killChrome' was never awaited\n",
      "  handle = None  # Needed to break cycles when an exception occurs.\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<frozen runpy>:198\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m(mod_name, alter_argv)\u001b[0m\n",
      "File \u001b[0;32m<frozen runpy>:88\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m(code, run_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel_launcher.py:17\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipykernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[0;32m---> 17\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_new_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/traitlets/config/application.py:1053\u001b[0m, in \u001b[0;36mApplication.launch_instance\u001b[0;34m(cls, argv, **kwargs)\u001b[0m\n\u001b[1;32m   1051\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39minstance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1052\u001b[0m app\u001b[38;5;241m.\u001b[39minitialize(argv)\n\u001b[0;32m-> 1053\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/kernelapp.py:736\u001b[0m, in \u001b[0;36mIPKernelApp.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tornado/platform/asyncio.py:195\u001b[0m, in \u001b[0;36mBaseAsyncIOLoop.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masyncio_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:607\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m events\u001b[38;5;241m.\u001b[39m_set_running_loop(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:1884\u001b[0m, in \u001b[0;36mBaseEventLoop._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1881\u001b[0m     when \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when\n\u001b[1;32m   1882\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime()), MAXIMUM_SELECT_TIMEOUT)\n\u001b[0;32m-> 1884\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;66;03m# Needed to break cycles when an exception occurs.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py:566\u001b[0m, in \u001b[0;36mKqueueSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     kev_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mcontrol(\u001b[38;5;28;01mNone\u001b[39;00m, max_ev, timeout)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyppeteer/launcher.py:153\u001b[0m, in \u001b[0;36mLauncher.launch.<locals>._close_process\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_close_process\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchromeClosed:\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkillChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:629\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    632\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:588\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the username and password from the environment variables\n",
    "username = os.getenv('USERNAME')  # Make sure to define your credentials in a .env file\n",
    "password = os.getenv('PASSWORD')\n",
    "\n",
    "\n",
    "\n",
    "# Async function to create session and login\n",
    "async def create_session_and_login():\n",
    "    # Create an AsyncHTMLSession object\n",
    "    session = AsyncHTMLSession()\n",
    "\n",
    "    # URL of the login page\n",
    "    login_url = \"https://www.marketscreener.com/login/\"\n",
    "\n",
    "    # Replace with the actual form data required for login\n",
    "    payload = {\n",
    "        'login': username,  # Use the actual login field from the form\n",
    "        'password': password\n",
    "    }\n",
    "\n",
    "    # Headers to mimic a browser request\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "    # Submit login form\n",
    "    response = await session.post(login_url, data=payload, headers=headers)\n",
    "\n",
    "    # Render JavaScript (if required by the page)\n",
    "    await response.html.arender()\n",
    "\n",
    "    # Check if login was successful by looking for \"logout\" in the page\n",
    "    if \"logout\" in response.text:\n",
    "        print(\"Login successful!\")\n",
    "    else:\n",
    "        print(\"Login failed. Check your credentials or login process.\")\n",
    "    \n",
    "    await asyncio.sleep(10)  # Be polite to the server by adding a small delay\n",
    "    \n",
    "\n",
    "    return session\n",
    "\n",
    "# Async function to get recommendation URLs from a page\n",
    "async def get_recommendation_urls_from_page(session, url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    \n",
    "    # Use session.get to maintain the login state\n",
    "    page = await session.get(url, headers=headers)\n",
    "    \n",
    "    # Render JavaScript content (important for dynamically-loaded content)\n",
    "    await page.html.arender()\n",
    "\n",
    "    # Use BeautifulSoup to parse the rendered content\n",
    "    soup = BeautifulSoup(page.html.html, 'html.parser')\n",
    "\n",
    "    # Print session cookies for debugging\n",
    "    print(session.cookies.get_dict())\n",
    "\n",
    "    # Find all recommendation links (adjust the HTML structure if necessary)\n",
    "    links = soup.find_all('a', href=True)\n",
    "    recommendation_urls = []\n",
    "    \n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        # Only include links with '/quote/stock/' and '/news/' but exclude '/news/hot-news/'\n",
    "        if '/quote/stock/' in href and '/news/' in href and '/news/hot-news/' not in href:\n",
    "            full_url = 'https://www.marketscreener.com' + href\n",
    "            recommendation_urls.append(full_url)\n",
    "\n",
    "    return recommendation_urls\n",
    "\n",
    "# Async function to loop through multiple pages and get recommendation URLs\n",
    "async def get_all_recommendation_urls(base_url, cf_param, session, max_pages=1):\n",
    "    all_recommendation_urls = []\n",
    "    \n",
    "    for p in range(1, max_pages + 1):\n",
    "        # Correctly formatted URL with both p and cf parameters\n",
    "        page_url = f\"{base_url}?p={p}&cf={cf_param}\"\n",
    "        print(f\"Scraping page {p}: {page_url}\")\n",
    "        \n",
    "        # Get recommendation URLs from the current page\n",
    "        recommendation_urls = await get_recommendation_urls_from_page(session, page_url)\n",
    "        \n",
    "        # If no URLs are found on this page, stop the loop\n",
    "        if not recommendation_urls:\n",
    "            print(f\"No more recommendations found at page {p}. Stopping.\")\n",
    "            break\n",
    "        \n",
    "        all_recommendation_urls.extend(recommendation_urls)\n",
    "        await asyncio.sleep(2)  # Be polite to the server by adding a small delay\n",
    "\n",
    "    return all_recommendation_urls\n",
    "\n",
    "# Async function to scrape individual recommendation pages\n",
    "async def scrape_recommendation_page(url, session):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "    try:\n",
    "        # Use session.get instead of requests.get to maintain the login state\n",
    "        page = await session.get(url, headers=headers)\n",
    "\n",
    "        # Render JavaScript (if required)\n",
    "        await page.html.arender()\n",
    "\n",
    "        # Parse the page with BeautifulSoup\n",
    "        soup = BeautifulSoup(page.html.html, 'html.parser')\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching page {url}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract the published date\n",
    "    date_div = soup.find('div', class_='c-6 mb-15')\n",
    "    published_date = date_div.get_text().strip() if date_div else 'No Date'\n",
    "    \n",
    "    # Check if the published date is in \"September ... 2024\"\n",
    "    if re.search(r'September.*2024', published_date) or re.search(r'\\d{2}\\.09\\.2024', published_date) or re.search(r'\\d{2}\\.10\\.2024', published_date) or re.search(r'October.*2024', published_date):\n",
    "        print(f\"Skipping page {url}: Published in September 2024\")\n",
    "        return None  # Skip this page\n",
    "\n",
    "    # Extract the title\n",
    "    title_tag = soup.find('h1', class_='title title__primary mb-15 txt-bold')\n",
    "    title = title_tag.get_text().strip() if title_tag else 'No Title'\n",
    "\n",
    "    # Extract the full text\n",
    "    full_text_div = soup.find('div', class_='txt-s4 article-text')\n",
    "    full_text = full_text_div.get_text().strip() if full_text_div else 'No Content'\n",
    "\n",
    "    # Skip if the title or full text is 'No Content'\n",
    "    if full_text == 'No Content':\n",
    "        print(f\"Skipping page {url}: Missing content\")\n",
    "        return None\n",
    "\n",
    "    # Extract the source\n",
    "    source_div = soup.find('div', class_='c-auto mb-15 txt-align-right txt-s2')\n",
    "    source = source_div.get_text().strip() if source_div else 'No Source'\n",
    "\n",
    "    # Extract the company name\n",
    "    company_name_header = soup.find('h2', class_='m-0 txt-s1 txt-b5')\n",
    "    company_name = company_name_header.get_text().strip() if company_name_header else 'No Company Name'\n",
    "\n",
    "    additional_infos = soup.find_all('div', class_='c-auto txt-align-right txt-bold')\n",
    "    if additional_infos:\n",
    "        additional_infos_all = [info.get_text().strip() for info in additional_infos]\n",
    "        mean_consensus = additional_infos_all[0] if len(additional_infos_all[0]) > 0 else 'No Mean Consensus'\n",
    "        number_of_analysts = additional_infos_all[1] if len(additional_infos_all[1]) > 0 else 'No Number of Analysts'\n",
    "        last_closed_price = additional_infos_all[2] if len(additional_infos_all[2]) > 0 else 'No Last Closed price'\n",
    "        average_target_price = additional_infos_all[3] if len(additional_infos_all[3]) > 0 else 'No Average Target Price'\n",
    "        spread = additional_infos_all[4] if len(additional_infos_all[4]) > 0 else 'No Spread'\n",
    "\n",
    "    # Extract company information (handle case where not found)\n",
    "    company_information_badges = soup.find_all('h2', class_='m-0 badge txt-b5 txt-s1')\n",
    "    if company_information_badges:\n",
    "        company_information = [badge.get_text().strip() for badge in company_information_badges]\n",
    "        company_name_short = company_information[0] if len(company_information) > 0 else 'No Content'\n",
    "        company_id = company_information[1] if len(company_information) > 1 else 'No Content'\n",
    "    else:\n",
    "        company_name_short = 'No Content'\n",
    "        company_id = 'No Content'\n",
    "\n",
    "    # Extract industry information (handle case where not found)\n",
    "    industry_badges = soup.find_all('h2', class_='m-0 txt-b5 txt-s1')\n",
    "    if industry_badges:\n",
    "        industry_information = [badge.get_text().strip() for badge in industry_badges]\n",
    "        industry_general = industry_information[0] if len(industry_information) > 0 else 'No Industry General'\n",
    "        industry = industry_information[1] if len(industry_information) > 1 else 'No industry tag'\n",
    "    else:\n",
    "        industry_general = 'No Industry General'\n",
    "        industry = 'No industry tag'\n",
    "    \n",
    "    # Return the results as a dictionary\n",
    "    return {\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'published_date': published_date,\n",
    "        'full_text': full_text,\n",
    "        'source': source,\n",
    "        'company_name': company_name,\n",
    "        'company_name_short': company_name_short,\n",
    "        'company_id': company_id,\n",
    "        'industry_general': industry_general,\n",
    "        'industry': industry,\n",
    "        'mean_consensus': mean_consensus,\n",
    "        'number_of_analysts': number_of_analysts,\n",
    "        'last_closed_price': last_closed_price,\n",
    "        'average_target_price': average_target_price,\n",
    "        'spread': spread\n",
    "    }\n",
    "\n",
    "# Async function to scrape all recommendations\n",
    "async def scrape_all_recommendations(urls, session):\n",
    "    data = []\n",
    "    \n",
    "    for url in urls:\n",
    "        try:\n",
    "            recommendation_data = await scrape_recommendation_page(url, session)\n",
    "            if recommendation_data:  # Only add if not None (i.e., not skipped)\n",
    "                data.append(recommendation_data)\n",
    "                print(f\"Scraped: {recommendation_data['title']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping page {url}: {e}\")\n",
    "            await asyncio.sleep(2)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Async function to run the whole process\n",
    "async def main():\n",
    "    timeframe_cf_param = 'aVQwZTQzL1hkU0JOTloyNTNWTERkK0dzUlJtNWk0VjdHaHhrMk9LOXVSUkRpMXBLa3o2b0xhcHNzT3ZwdnF3VDhEbjhTelpKMlNMcitDNFNORE5aT2REL0NsZWlENytrK2EySElPUTh6U3R6MDhmdm10UkdPSUtmQldWTnhvVnY'\n",
    "    base_url = 'https://www.marketscreener.com/news/companies/recommandations/'\n",
    "    \n",
    "    # Create session and log in\n",
    "    session = await create_session_and_login()\n",
    "\n",
    "    # Get all recommendation URLs\n",
    "    all_recommendation_urls = await get_all_recommendation_urls(base_url, timeframe_cf_param, session, max_pages=1)\n",
    "    \n",
    "    # Scrape all recommendation pages\n",
    "    recommendation_data = await scrape_all_recommendations(all_recommendation_urls, session)\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df = pd.DataFrame(recommendation_data)\n",
    "    print(df.head())  # Preview the DataFrame\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('/Users/oskarroeske/Masterthesis/scraped_data_us_market/analyst_recommendations_login_test3.csv', index=False)\n",
    "    print(\"Data saved\")\n",
    "\n",
    "# Execute the main function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
