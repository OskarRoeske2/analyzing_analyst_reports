{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def get_recommendation_urls_from_page(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Find all recommendation links (adjust the HTML structure if necessary)\n",
    "    links = soup.find_all('a', href=True)\n",
    "    recommendation_urls = []\n",
    "    \n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        # Only include links with '/quote/stock/' and '/news/' but exclude '/news/hot-news/'\n",
    "        if '/quote/stock/' in href and '/news/' in href and '/news/hot-news/' not in href:\n",
    "            full_url = 'https://www.marketscreener.com' + href\n",
    "            recommendation_urls.append(full_url)\n",
    "\n",
    "    return recommendation_urls\n",
    "\n",
    "# Function to loop through multiple pages with correct URL formatting\n",
    "def get_all_recommendation_urls(base_url, cf_param, max_pages=100):\n",
    "    all_recommendation_urls = []\n",
    "    \n",
    "    for p in range(1, max_pages + 1):\n",
    "        # Correctly formatted URL with both p and cf parameters\n",
    "        page_url = f\"{base_url}?p={p}&cf={cf_param}\"\n",
    "        print(f\"Scraping page {p}: {page_url}\")\n",
    "        recommendation_urls = get_recommendation_urls_from_page(page_url)\n",
    "        \n",
    "        # If no URLs are found on this page, stop the loop\n",
    "        if not recommendation_urls:\n",
    "            print(f\"No more recommendations found at page {p}. Stopping.\")\n",
    "            break\n",
    "        \n",
    "        all_recommendation_urls.extend(recommendation_urls)\n",
    "        time.sleep(2)  # Be polite to the server by adding a small delay\n",
    "\n",
    "    return all_recommendation_urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1: https://www.marketscreener.com/news/companies/recommandations/?p=1&cf=aVQwZTQzL1hkU0JOTloyNTNWTERkd2VZaU85L21hdjAyd2o1UFlhNnF1UEJHZkdOcjlqZG50WllEL25yUGZkd3g3Q3FYY1lIeE4vVXlDNkJUbExWRzVtNmtMV09wdkc3eW51R2VYY3FmaDg9\n",
      "Scraping page 2: https://www.marketscreener.com/news/companies/recommandations/?p=2&cf=aVQwZTQzL1hkU0JOTloyNTNWTERkd2VZaU85L21hdjAyd2o1UFlhNnF1UEJHZkdOcjlqZG50WllEL25yUGZkd3g3Q3FYY1lIeE4vVXlDNkJUbExWRzVtNmtMV09wdkc3eW51R2VYY3FmaDg9\n",
      "Total recommendation URLs found: 172\n"
     ]
    }
   ],
   "source": [
    "# Example Usage of Part 1:\n",
    "base_url = 'https://www.marketscreener.com/news/companies/recommandations/'\n",
    "cf_param = 'aVQwZTQzL1hkU0JOTloyNTNWTERkd2VZaU85L21hdjAyd2o1UFlhNnF1UEJHZkdOcjlqZG50WllEL25yUGZkd3g3Q3FYY1lIeE4vVXlDNkJUbExWRzVtNmtMV09wdkc3eW51R2VYY3FmaDg9'\n",
    "all_recommendation_urls = get_all_recommendation_urls(base_url, cf_param, max_pages=2)\n",
    "\n",
    "print(f\"Total recommendation URLs found: {len(all_recommendation_urls)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape the title, published date, and other details\n",
    "def scrape_recommendation_page(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Extract the title\n",
    "    title_tag = soup.find('h1', class_='title title__primary mb-15 txt-bold')\n",
    "    title = title_tag.get_text().strip() if title_tag else 'No Title'\n",
    "    \n",
    "    # Extract the published date\n",
    "    date_div = soup.find('div', class_='c-6 mb-15')\n",
    "    published_date = date_div.get_text().strip() if date_div else 'No Date'\n",
    "    \n",
    "    # Extract the full text\n",
    "    full_text_div = soup.find('div', class_='txt-s4 article-text')\n",
    "    full_text = full_text_div.get_text().strip() if full_text_div else 'No Content'\n",
    "\n",
    "    # Extract the source\n",
    "    source_div = soup.find('div', class_='c-auto mb-15 txt-align-right txt-s2')\n",
    "    source = source_div.get_text().strip() if source_div else 'No Source'\n",
    "\n",
    "    # Extract the company name\n",
    "    company_name_header = soup.find('h2', class_='m-0 txt-s1 txt-b5')\n",
    "    company_name = company_name_header.get_text().strip() if company_name_header else 'No Company Name'\n",
    "\n",
    "    # Extract company information\n",
    "    company_information_badges = soup.find_all('h2', class_='m-0 badge txt-b5 txt-s1')\n",
    "    company_information = [badge.get_text().strip() for badge in company_information_badges] if company_information_badges else ['No Content']\n",
    "    company_name_short = company_information[0] if len(company_information) > 0 else 'No Content'\n",
    "    company_id = company_information[1] if len(company_information) > 1 else 'No Content'\n",
    "\n",
    "    # Extract industry information\n",
    "    industry_badges = soup.find_all('h2', class_='m-0 txt-b5 txt-s1')\n",
    "    industry_information = [badge.get_text().strip() for badge in industry_badges] if industry_badges else ['No Content']\n",
    "    industry_general = industry_information[0] if len(industry_information) > 0 else 'No Industry General'\n",
    "    industry = industry_information[1] if len(industry_information) > 1 else 'No industry tag'\n",
    "    \n",
    "    # Return the results as a dictionary\n",
    "    return {\n",
    "        'url': url,\n",
    "        'title': title,\n",
    "        'published_date': published_date,\n",
    "        'full_text': full_text,\n",
    "        'source': source,\n",
    "        'company_name': company_name,\n",
    "        'company_name_short': company_name_short,\n",
    "        'company_id': company_id,\n",
    "        'industry_general': industry_general,\n",
    "        'industry': industry\n",
    "    }\n",
    "\n",
    "# Scrape all the recommendations from the provided URLs\n",
    "def scrape_all_recommendations(urls):\n",
    "    data = []\n",
    "    \n",
    "    for url in urls:\n",
    "        try:\n",
    "            recommendation_data = scrape_recommendation_page(url)\n",
    "            data.append(recommendation_data)\n",
    "            print(f\"Scraped: {recommendation_data['title']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape {url}: {e}\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped: The Children's Place, Inc. Reports Earnings Results for the Second Quarter and Six Months Ended August 03, 2024\n",
      "Scraped: Meme stock GameStop slumps as revenue drop fans turnaround doubts\n",
      "Scraped: Designer Brands Inc. Revises Earnings Guidance for the Full Year 2024\n",
      "Scraped: Viva Leisure Limited signed a letter of intent to acquire 34% stake in Boutique Fitness Studio from Xponential Fitness, Inc. for AUD 2 million.\n",
      "Scraped: Manchester United plc Provides Earnings Guidance for the Fiscal Year 2025\n",
      "Scraped: MultiPlan Corporation Announces Resignation of Glenn R. August as Member of the Board of Directors\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Hybar LLC announced that it has received funding from Quanta Services, Inc.\n",
      "Scraped: Vera Bradley, Inc. Provides Consolidated Earnings Guidance for the Fiscal Year Ending February 1, 2025\n",
      "Scraped: Femasys, Inc. Secures Strategic Distribution Partnerships for Commercialization of FemaSeed for over $1.3 Million in Spanish Market\n",
      "Scraped: Cimpress plc Announces Offering of $525 Million of Senior Notes Due 2032\n",
      "Scraped: BridgeBio Pharma, Inc. Reports Topline Results from Phase 1/2 Trial of Investigational Gene Therapy for Congenital Adrenal Hyperplasia\n",
      "Scraped: Visa aims for 10-fold rise in Pakistani use of digital payments\n",
      "Scraped: Applied DNA Sciences, Inc.'s Applied DNA Clinical Labs, LLC Launches Mpox Clade I and Clade II Testing Service\n",
      "Scraped: Fox News proposes second presidential debate in October\n",
      "Scraped: AIM WINNERS & LOSERS: Anpario rises; Pebble Beach teams with Nvidia\n",
      "Scraped: US Postal Service to end discounted rates for package consolidators\n",
      "Scraped: Venture capital fund ends grant program supporting Black women after lawsuit\n",
      "Scraped: How regulators have overhauled contentious Basel Endgame capital hike rule\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Expedia Group, Inc. Announces Resignation of Peter Kern as Vice Chairman and Board member\n",
      "Scraped: McDonald's Rolling Out Kiosks That Take Cash, Bloomberg Reports\n",
      "Scraped: GE Vernova: containerized battery storage solution\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Lockheed Martin: contract for 3 radars with Norway\n",
      "Scraped: German parliament approves rescue of shipbuilder Meyer Werft, lawmakers say\n",
      "Scraped: J&J: positive trial for dexamethasone\n",
      "Scraped: Dollarama Inc. Approves Quarterly Cash Dividend, Payable on November 1, 2024\n",
      "Scraped: New Gold Inc. Expands Open Pit and Underground Mineralization At Rainy River, Demonstrates Strong Support for Mineral Resources Growth\n",
      "Scraped: Engine Capital Sends Letter to Dye & Durham?s Board of Directors\n",
      "Scraped: Canadian National Railway says its operations have recovered from work stoppages\n",
      "Scraped: POET Technologies Inc. Announces its Selection by Mentech to Supply Engines for 800G and 1.6T Optical Modules\n",
      "Scraped: Talisker Resources Ltd. announced that it has received CAD 2.5202 million in funding\n",
      "Scraped: Sun Life Announces Leadership Changes for Sun Life Canada\n",
      "Scraped: Business groups urge Ottawa to prevent Air Canada pilots strike\n",
      "Scraped: T.Rowe Price backs Disney directors in boardroom challenge with hedge funds\n",
      "Scraped: FedEx to Let Contract With USPS Lapse; UPS Strikes Deal\n",
      "Scraped: UPS to become United States Postal Service's primary air cargo provider\n",
      "Scraped: SoftwareOne says its board plan backed by ISS amid power struggle\n",
      "Scraped: Japanese banks less reluctant to finance hostile takeovers, lobby chief says\n",
      "Scraped: US pension fund CalPERS backs Peltz, Rasulo in Disney board battle\n",
      "Scraped: US pension fund CalPERS votes for Peltz, Rasulo in Disney boardroom fight\n",
      "Scraped: No Title\n",
      "Scraped: Strike at Lufthansa subsidiary AUA over for the time being\n",
      "Scraped: No Title\n",
      "Scraped: Conduit Holdings CEO Trevor Carvey buys GBP95,000 in shares\n",
      "Scraped: Pollen Street's Matthew Potter sells GBP1 million in shares\n",
      "Scraped: General Dynamics Unit Awarded $922 Million Contract to Modernize CENTCOM Infrastructure\n",
      "Scraped: Blackwells sues Disney in Delaware over disclosure in relationship with ValueAct\n",
      "Scraped: Estée Lauder Shares Climb 6.2% Following Bank of America's Upgrade on Turnaround Efforts\n",
      "Scraped: New York City Retirement System to back Disney in boardroom battle with Trian, Blackwells\n",
      "Scraped: Tatton Asset Management CEO sells GBP1.1 million in shares\n",
      "Scraped: EASYJET  :  JP Morgan maintains a Buy rating\n",
      "Scraped: PERNOD RICARD  :  UBS remains Neutral\n",
      "Scraped: CANCOM  :  Raised by DZ Bank\n",
      "Scraped: ZURICH INSURANCE GROUP  :  Jefferies gives a Neutral rating\n",
      "Scraped: Reckitt Benckiser: in green, a broker confirms its recommendation\n",
      "Scraped: LANXESS AG  :  UBS reaffirms its Neutral rating\n",
      "Scraped: Arkema: BlackRock crosses the 5% threshold\n",
      "Scraped: HORNBACH HOLDING  :  DZ Bank reiterates its Buy rating\n",
      "Scraped: Estée Lauder: S&P's biggest gainer, BofA upgrades to buy\n",
      "Scraped: BT Group CEO Allison Kirkby buys GBP55,000 in shares\n",
      "Scraped: RICHEMONT  :  Jefferies reaffirms its Buy rating\n",
      "Scraped: TESLA  :  Deutsche Bank keeps its Buy rating\n",
      "Scraped: INTESA SANPAOLO S.P.A.  :  Buy rating from DZ Bank\n",
      "Scraped: Warburg Research raises target for Suess Microtec to 45 euros - 'Buy'\n",
      "Scraped: SCHNEIDER ELECTRIC :  Morgan Stanley raises its target\n",
      "Scraped: ENI  :  RBC sticks Neutral\n",
      "Scraped: KERING  :  RBC reaffirms its Buy rating\n",
      "Scraped: SHELL (NEU)  :  RBC remains its Buy rating\n",
      "Scraped: Baader Bank rates Jungheinrich as 'Add' - Target 31 euros\n",
      "Scraped: UBS AG  :  RBC gives a Buy rating\n",
      "Scraped: TESLA :  Wedbush cuts its price target\n",
      "Scraped: NIKE INC  :  RBC reaffirms its Neutral rating\n",
      "Scraped: FERRARI  :  Buy rating from RBC\n",
      "Scraped: PUMA SE  :  RBC reaffirms its Neutral rating\n",
      "Scraped: RICHEMONT  :  RBC reaffirms its Neutral rating\n",
      "Scraped: Goldman raises target for Siemens Energy to 27 euros - 'Buy'\n",
      "Scraped: ADIDAS  :  RBC reiterates its Buy rating\n",
      "Scraped: LVMH  :  RBC reiterates its Buy rating\n",
      "Scraped: PERNOD RICARD  :  Buy rating from Jefferies\n",
      "Scraped: ESSILORLUXOTTICA  :  Gets a Neutral rating from RBC\n",
      "Scraped: AMAZON COM INC  :  Jefferies keeps its Buy rating\n",
      "Scraped: UPS  :  Jefferies maintains a Buy rating\n",
      "Scraped: RECKITT BENCKISER :  Jefferies raises target price\n",
      "Scraped: The Children's Place, Inc. Reports Earnings Results for the Second Quarter and Six Months Ended August 03, 2024\n",
      "Scraped: Meme stock GameStop slumps as revenue drop fans turnaround doubts\n",
      "Scraped: Designer Brands Inc. Revises Earnings Guidance for the Full Year 2024\n",
      "Scraped: Viva Leisure Limited signed a letter of intent to acquire 34% stake in Boutique Fitness Studio from Xponential Fitness, Inc. for AUD 2 million.\n",
      "Scraped: Manchester United plc Provides Earnings Guidance for the Fiscal Year 2025\n",
      "Scraped: MultiPlan Corporation Announces Resignation of Glenn R. August as Member of the Board of Directors\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Hybar LLC announced that it has received funding from Quanta Services, Inc.\n",
      "Scraped: Vera Bradley, Inc. Provides Consolidated Earnings Guidance for the Fiscal Year Ending February 1, 2025\n",
      "Scraped: Femasys, Inc. Secures Strategic Distribution Partnerships for Commercialization of FemaSeed for over $1.3 Million in Spanish Market\n",
      "Scraped: Cimpress plc Announces Offering of $525 Million of Senior Notes Due 2032\n",
      "Scraped: BridgeBio Pharma, Inc. Reports Topline Results from Phase 1/2 Trial of Investigational Gene Therapy for Congenital Adrenal Hyperplasia\n",
      "Scraped: Visa aims for 10-fold rise in Pakistani use of digital payments\n",
      "Scraped: Applied DNA Sciences, Inc.'s Applied DNA Clinical Labs, LLC Launches Mpox Clade I and Clade II Testing Service\n",
      "Scraped: Fox News proposes second presidential debate in October\n",
      "Scraped: AIM WINNERS & LOSERS: Anpario rises; Pebble Beach teams with Nvidia\n",
      "Scraped: US Postal Service to end discounted rates for package consolidators\n",
      "Scraped: Venture capital fund ends grant program supporting Black women after lawsuit\n",
      "Scraped: How regulators have overhauled contentious Basel Endgame capital hike rule\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Expedia Group, Inc. Announces Resignation of Peter Kern as Vice Chairman and Board member\n",
      "Scraped: McDonald's Rolling Out Kiosks That Take Cash, Bloomberg Reports\n",
      "Scraped: GE Vernova: containerized battery storage solution\n",
      "Scraped: Ex-dividend day\n",
      "Scraped: Lockheed Martin: contract for 3 radars with Norway\n",
      "Scraped: German parliament approves rescue of shipbuilder Meyer Werft, lawmakers say\n",
      "Scraped: J&J: positive trial for dexamethasone\n",
      "Scraped: Dollarama Inc. Approves Quarterly Cash Dividend, Payable on November 1, 2024\n",
      "Scraped: New Gold Inc. Expands Open Pit and Underground Mineralization At Rainy River, Demonstrates Strong Support for Mineral Resources Growth\n",
      "Scraped: Engine Capital Sends Letter to Dye & Durham?s Board of Directors\n",
      "Scraped: Canadian National Railway says its operations have recovered from work stoppages\n",
      "Scraped: POET Technologies Inc. Announces its Selection by Mentech to Supply Engines for 800G and 1.6T Optical Modules\n",
      "Scraped: Talisker Resources Ltd. announced that it has received CAD 2.5202 million in funding\n",
      "Scraped: Sun Life Announces Leadership Changes for Sun Life Canada\n",
      "Scraped: Business groups urge Ottawa to prevent Air Canada pilots strike\n",
      "Scraped: Vodafone Chair Boxmeer buys GBP570,000 in shares\n",
      "Scraped: LEGRAND :  Morgan Stanley upgrades to 'Overweight\n",
      "Scraped: Goldman raises target for Symrise to 101 euros - 'Sell'\n",
      "Scraped: Holcim: in the green with broker upgrade\n",
      "Scraped: No Title\n",
      "Scraped: SCHNEIDER ELECTRIC  :  RBC maintains a Sell rating\n",
      "Scraped: RECKITT  :  Receives a Buy rating from Barclays\n",
      "Scraped: H&M  :  Receives a Buy rating from Barclays\n",
      "Scraped: SARTORIUS VORZUEGE  :  Barclays reaffirms its Neutral rating\n",
      "Scraped: SilverBow Resources rejects Kimmeridge's $2.1 billion takeover offer\n",
      "Scraped: H&M  :  Goldman Sachs remains a Sell rating\n",
      "Scraped: SIEMENS ENERGY  :  Buy rating from Goldman Sachs\n",
      "Scraped: SYMRISE AG  :  Gets a Sell rating from Goldman Sachs\n",
      "Scraped: RECKITT  :  UBS maintains a Buy rating\n",
      "Scraped: SANOFI  :  Barclays reiterates its Buy rating\n",
      "Scraped: NOVARTIS AG  :  Barclays gives a Sell rating\n",
      "Scraped: HENKEL VORZUEGE  :  UBS reiterates its Neutral rating\n",
      "Scraped: SCHNEIDER ELECTRIC  :  Receives a Buy rating from UBS\n",
      "Scraped: AKZO NOBEL NV  :  UBS reiterates its Neutral rating\n",
      "Scraped: ENI  :  UBS gives a Buy rating\n",
      "Scraped: No Title\n",
      "Scraped: PHILIPS NV  :  Sell rating from Deutsche Bank\n",
      "Scraped: LOREAL  :  Gets a Sell rating from Deutsche Bank\n",
      "Scraped: ASTRAZENECA  :  Deutsche Bank reiterates its Sell rating\n",
      "Scraped: H&M  :  Deutsche Bank reaffirms its Sell rating\n",
      "Scraped: KION  :  Deutsche Bank reiterates its Buy rating\n",
      "Scraped: SIEMENS AG  :  Buy rating from Deutsche Bank\n",
      "Scraped: EVONIK  :  Deutsche Bank gives a Buy rating\n",
      "Scraped: AIXTRON  :  Deutsche Bank remains its Buy rating\n",
      "Scraped: SÜSS MICROTEC  :  Warburg Research reiterates its Buy rating\n",
      "Scraped: JENOPTIK AG  :  Warburg Research reaffirms its Buy rating\n",
      "Scraped: PNE AG  :  Gets a Buy rating from Warburg Research\n",
      "Scraped: KION  :  Receives a Buy rating from Warburg Research\n",
      "Scraped: ATOSS SOFTWARE AG  :  Buy rating from Warburg Research\n",
      "Scraped: BASLER AG  :  Receives a Buy rating from Warburg Research\n",
      "Scraped: STRATEC BIOMEDICAL SYSTEMS AG  :  Gets a Neutral rating from Warburg Research\n",
      "Scraped: KONTRON  :  Buy rating from Warburg Research\n",
      "Scraped: ENERGIEKONTOR AG  :  Buy rating from Warburg Research\n",
      "Scraped: JUNGHEINRICH AG  :  Warburg Research reiterates its Buy rating\n",
      "Scraped: BAYWA  :  Warburg Research reiterates its Buy rating\n",
      "Scraped: Berenberg rates Stratec at 'Hold' - Target 43 euros\n",
      "Scraped: No Title\n",
      "Scraped: STRATEC BIOMEDICAL SYSTEMS AG  :  Berenberg sticks Neutral\n",
      "Scraped: Memscap: profit-taking after in-line results\n",
      "Scraped: No Title\n",
      "Scraped: JUNGHEINRICH AG  :  Jefferies reiterates its Buy rating\n",
      "Scraped: KION  :  Jefferies remains its Buy rating\n",
      "Scraped: KONTRON  :  Buy rating from Jefferies\n",
      "Scraped: Legrand: leads the CAC, Morgan Stanley more optimistic\n",
      "Scraped: BASLER AG  :  Jefferies reiterates its Buy rating\n"
     ]
    }
   ],
   "source": [
    "# Example Usage of Part 3:\n",
    "recommendation_data = scrape_all_recommendations(all_recommendation_urls)\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(recommendation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'analyst_recommendations_test3.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/Users/oskarroeske/Masterthesis/scraped_data/analyst_recommendations_test3.csv', index=False)\n",
    "print(\"Data saved to 'analyst_recommendations_test3.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
