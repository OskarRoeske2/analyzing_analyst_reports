{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ace_tools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.0)\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.5.4)\n",
      "Requirement already satisfied: tabula in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.26.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.10.19)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (75.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pathy>=0.10.0->spacy) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ace_tools spacy tabula https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Relevant Files and models\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "provider_info = pd.read_csv('provider.csv')\n",
    "company_info = pd.read_csv('company_info.csv')\n",
    "\n",
    "company_info = company_info.drop_duplicates(subset='Ticker Symbol')\n",
    "\n",
    "# Create a dictionary to map ticker symbols to company name and industry\n",
    "ticker_map = company_info.set_index('Ticker Symbol')[['Company Name', 'Industry']].to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>file_name</th>\n",
       "      <th>Ending</th>\n",
       "      <th>Price Target</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGC Partners</td>\n",
       "      <td>BGC</td>\n",
       "      <td>Disclosures Appendix</td>\n",
       "      <td>Price Target ($) {price}</td>\n",
       "      <td>{RATING} ({TICKER},$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Needham</td>\n",
       "      <td>Needham</td>\n",
       "      <td>Analyst Certification</td>\n",
       "      <td>Price Target ${price}</td>\n",
       "      <td>Stock Rating {RATING}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTIG</td>\n",
       "      <td>BTIG</td>\n",
       "      <td>Appendix: Analyst Certification and Other Impo...</td>\n",
       "      <td>12 month target ${price}</td>\n",
       "      <td>{RATING} 52 week range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Wells_Fargo</td>\n",
       "      <td>Required Disclosures</td>\n",
       "      <td>Overweight/${price}</td>\n",
       "      <td>{Rating}/$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>ANALYST(S) CERTIFICATION(S)</td>\n",
       "      <td>Price Target USD {price}</td>\n",
       "      <td>Stock Rating {RATING}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JP Morgan</td>\n",
       "      <td>JP_Morgan</td>\n",
       "      <td>Analyst Certification</td>\n",
       "      <td>Price Target ({Letters &amp; numbers}): ${price}</td>\n",
       "      <td>{Rating} {TICKER}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brean Capital</td>\n",
       "      <td>Brean_Capital</td>\n",
       "      <td>Analyst Certification</td>\n",
       "      <td>PT: $  {price}</td>\n",
       "      <td>{Rating} PT:$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hilliard Lyons</td>\n",
       "      <td>Hilliard_Lyons</td>\n",
       "      <td>Analyst Certification</td>\n",
       "      <td>Price Target {price}</td>\n",
       "      <td>NSYE -- {Rating} --</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alliance Global Partners</td>\n",
       "      <td>Alliance_Global_Partners</td>\n",
       "      <td>Imporant Research Disclosures</td>\n",
       "      <td>Price Target ${price}</td>\n",
       "      <td>{Rating} (Ticker:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mizuho Securities</td>\n",
       "      <td>Mizuho_Securities</td>\n",
       "      <td>IMPORTANT DISCLOSURES</td>\n",
       "      <td>Price Target ${price}</td>\n",
       "      <td>Rating Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gilford Securities Inc</td>\n",
       "      <td>Gilford_Securities_Inc</td>\n",
       "      <td>ANALYST CERTIFICATION</td>\n",
       "      <td>-</td>\n",
       "      <td>BUY OR Rated:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>Deutsche_Bank</td>\n",
       "      <td>Appendix 1</td>\n",
       "      <td>Price Target (USD) {price}</td>\n",
       "      <td>Rating {Rating}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pivotal Research Group</td>\n",
       "      <td>Pivotal_Research_Group</td>\n",
       "      <td>Appendix: Important Disclosures</td>\n",
       "      <td>Target Price: ${price}</td>\n",
       "      <td>RATING: {RATING}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Spartan Capital Securities LLC</td>\n",
       "      <td>Spartan_Capital_Securities_LLC</td>\n",
       "      <td>Important Disclosures</td>\n",
       "      <td>T ${price}</td>\n",
       "      <td>{Rating}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cascend Securities -Historical-</td>\n",
       "      <td>Cascend_Securities_-Historical-</td>\n",
       "      <td>Disclosures:</td>\n",
       "      <td>Price target: ${price}</td>\n",
       "      <td>Rating: {RATING}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Phillip Securities</td>\n",
       "      <td>Phillip_Securities</td>\n",
       "      <td>Important Information</td>\n",
       "      <td>TARGET PRICE USD</td>\n",
       "      <td>{RATING} ({UPPERCASELETTERS})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FinTrust Investment Advisors</td>\n",
       "      <td>FinTrust_Investment_Advisors</td>\n",
       "      <td>Important Disclosures:</td>\n",
       "      <td>Target Price: ${price}</td>\n",
       "      <td>Fintrust Rating: {RATING}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IBI Investment House</td>\n",
       "      <td>IBI_Investment_House</td>\n",
       "      <td>Disclosures</td>\n",
       "      <td>Price target: ${price}</td>\n",
       "      <td>Recommendation: {Rating}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>APP Securities Pty LTd</td>\n",
       "      <td>APP_Securities_Pty_Ltd</td>\n",
       "      <td>Analyst Certification</td>\n",
       "      <td>TARGET PRICE</td>\n",
       "      <td>{RATING}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IFS Securities</td>\n",
       "      <td>IFS_Securities</td>\n",
       "      <td>Imporant Investor Disclosures:</td>\n",
       "      <td>Price Target: $</td>\n",
       "      <td>{Rating}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Provider                        file_name  \\\n",
       "0                      BGC Partners                              BGC   \n",
       "1                           Needham                          Needham   \n",
       "2                              BTIG                             BTIG   \n",
       "3                       Wells Fargo                      Wells_Fargo   \n",
       "4                          Barclays                         Barclays   \n",
       "5                         JP Morgan                        JP_Morgan   \n",
       "6                     Brean Capital                    Brean_Capital   \n",
       "7                    Hilliard Lyons                   Hilliard_Lyons   \n",
       "8          Alliance Global Partners         Alliance_Global_Partners   \n",
       "9                 Mizuho Securities                Mizuho_Securities   \n",
       "10           Gilford Securities Inc           Gilford_Securities_Inc   \n",
       "11                    Deutsche Bank                    Deutsche_Bank   \n",
       "12           Pivotal Research Group           Pivotal_Research_Group   \n",
       "13   Spartan Capital Securities LLC   Spartan_Capital_Securities_LLC   \n",
       "14  Cascend Securities -Historical-  Cascend_Securities_-Historical-   \n",
       "15               Phillip Securities               Phillip_Securities   \n",
       "16     FinTrust Investment Advisors     FinTrust_Investment_Advisors   \n",
       "17             IBI Investment House             IBI_Investment_House   \n",
       "18           APP Securities Pty LTd           APP_Securities_Pty_Ltd   \n",
       "19                   IFS Securities                   IFS_Securities   \n",
       "\n",
       "                                               Ending  \\\n",
       "0                                Disclosures Appendix   \n",
       "1                               Analyst Certification   \n",
       "2   Appendix: Analyst Certification and Other Impo...   \n",
       "3                                Required Disclosures   \n",
       "4                         ANALYST(S) CERTIFICATION(S)   \n",
       "5                               Analyst Certification   \n",
       "6                               Analyst Certification   \n",
       "7                               Analyst Certification   \n",
       "8                       Imporant Research Disclosures   \n",
       "9                               IMPORTANT DISCLOSURES   \n",
       "10                              ANALYST CERTIFICATION   \n",
       "11                                         Appendix 1   \n",
       "12                    Appendix: Important Disclosures   \n",
       "13                              Important Disclosures   \n",
       "14                                       Disclosures:   \n",
       "15                              Important Information   \n",
       "16                             Important Disclosures:   \n",
       "17                                        Disclosures   \n",
       "18                              Analyst Certification   \n",
       "19                     Imporant Investor Disclosures:   \n",
       "\n",
       "                                    Price Target  \\\n",
       "0                       Price Target ($) {price}   \n",
       "1                          Price Target ${price}   \n",
       "2                       12 month target ${price}   \n",
       "3                            Overweight/${price}   \n",
       "4                       Price Target USD {price}   \n",
       "5   Price Target ({Letters & numbers}): ${price}   \n",
       "6                                 PT: $  {price}   \n",
       "7                           Price Target {price}   \n",
       "8                          Price Target ${price}   \n",
       "9                          Price Target ${price}   \n",
       "10                                            -    \n",
       "11                    Price Target (USD) {price}   \n",
       "12                        Target Price: ${price}   \n",
       "13                                    T ${price}   \n",
       "14                        Price target: ${price}   \n",
       "15                              TARGET PRICE USD   \n",
       "16                        Target Price: ${price}   \n",
       "17                        Price target: ${price}   \n",
       "18                                  TARGET PRICE   \n",
       "19                               Price Target: $   \n",
       "\n",
       "                   Recommendation  \n",
       "0            {RATING} ({TICKER},$  \n",
       "1           Stock Rating {RATING}  \n",
       "2          {RATING} 52 week range  \n",
       "3                      {Rating}/$  \n",
       "4           Stock Rating {RATING}  \n",
       "5               {Rating} {TICKER}  \n",
       "6                 {Rating} PT:$    \n",
       "7             NSYE -- {Rating} --  \n",
       "8               {Rating} (Ticker:  \n",
       "9                      Rating Buy  \n",
       "10                 BUY OR Rated:   \n",
       "11                Rating {Rating}  \n",
       "12               RATING: {RATING}  \n",
       "13                       {Rating}  \n",
       "14               Rating: {RATING}  \n",
       "15  {RATING} ({UPPERCASELETTERS})  \n",
       "16      Fintrust Rating: {RATING}  \n",
       "17       Recommendation: {Rating}  \n",
       "18                       {RATING}  \n",
       "19                       {Rating}  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Only relevant to check font type and size for\\nimport pdfplumber\\n\\ndef extract_words_with_formatting(page):\\n\\n    # Extract words with their bounding boxes\\n    words = page.extract_words(extra_attrs=[\"fontname\", \"size\"])\\n\\n    formatted_words = []\\n    for word in words:\\n        formatted_words.append({\\n            \"word\": word[\"text\"],\\n            \"font\": word.get(\"fontname\", \"Unknown\"),\\n            \"size\": word.get(\"size\", \"Unknown\"),\\n            \"x0\": word[\"x0\"],\\n            \"x1\": word[\"x1\"],\\n            \"top\": word[\"top\"],\\n            \"bottom\": word[\"bottom\"]\\n        })\\n    return formatted_words\\n\\n\\n# Example usage with pdfplumber\\npdf_path = \"/Users/oskarroeske/Desktop/Analyst_Reports/Staging/20220803_Phillip_Securities_AAPL_Apple_Inc_Managing_supply_chain_and_FX_headwinds_we.pdf\"\\n\\nwith pdfplumber.open(pdf_path) as pdf:\\n    for page_number, page in enumerate(pdf.pages, start=1):\\n        print(f\"Page {page_number}:\")\\n        formatted_words = extract_words_with_formatting(page)\\n        for word_info in formatted_words:\\n            print(\\n                f\"Word: \\'{word_info[\\'word\\']}\\', Font: {word_info[\\'font\\']}, Size: {word_info[\\'size\\']}, \"\\n                f\"Position: ({word_info[\\'x0\\']}, {word_info[\\'top\\']} - {word_info[\\'x1\\']}, {word_info[\\'bottom\\']})\"\\n            )\\n'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Only relevant to check font type and size for\n",
    "import pdfplumber\n",
    "\n",
    "def extract_words_with_formatting(page):\n",
    "\n",
    "    # Extract words with their bounding boxes\n",
    "    words = page.extract_words(extra_attrs=[\"fontname\", \"size\"])\n",
    "\n",
    "    formatted_words = []\n",
    "    for word in words:\n",
    "        formatted_words.append({\n",
    "            \"word\": word[\"text\"],\n",
    "            \"font\": word.get(\"fontname\", \"Unknown\"),\n",
    "            \"size\": word.get(\"size\", \"Unknown\"),\n",
    "            \"x0\": word[\"x0\"],\n",
    "            \"x1\": word[\"x1\"],\n",
    "            \"top\": word[\"top\"],\n",
    "            \"bottom\": word[\"bottom\"]\n",
    "        })\n",
    "    return formatted_words\n",
    "\n",
    "\n",
    "# Example usage with pdfplumber\n",
    "pdf_path = \"/Users/oskarroeske/Desktop/Analyst_Reports/Staging/20220803_Phillip_Securities_AAPL_Apple_Inc_Managing_supply_chain_and_FX_headwinds_we.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_number, page in enumerate(pdf.pages, start=1):\n",
    "        print(f\"Page {page_number}:\")\n",
    "        formatted_words = extract_words_with_formatting(page)\n",
    "        for word_info in formatted_words:\n",
    "            print(\n",
    "                f\"Word: '{word_info['word']}', Font: {word_info['font']}, Size: {word_info['size']}, \"\n",
    "                f\"Position: ({word_info['x0']}, {word_info['top']} - {word_info['x1']}, {word_info['bottom']})\"\n",
    "            )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test new Structure\n",
    "\n",
    "patterns = {\n",
    "    \"APP Securities Pty Ltd\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"TARGET PRICE (NA|\\$(\\d+(\\.\\d+)?))\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(BUY|HOLD|SELL|OVERWEIGHT|UNDERPERFORM)\\b\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Analyst Certification\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(,Bold)?\", \"font_size\": 8.04},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(,Bold)?\", \"font_size\": 8.25},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Alliance Global Partners\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target (NA|\\$(\\d+(\\.\\d+)?))\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(Buy|Hold|Sell|Overweight|Underperform)\\b\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Imporant Research Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]ArialMT(-BoldMT)?\", \"font_size\": 8.00},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Barclays\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target USD (\\d+(\\.\\d+)?)\",\n",
    "            \"secondary\": r\"Price Target: USD (\\d+(\\.\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"Stock Rating ([A-Za-z]+)\",\n",
    "            \"secondary\": r\"\\b(BUY|HOLD|SELL|OVERWEIGHT|OVERPERFORM|UNDERPERFORM|UNDERWEIGHT|NEUTRAL)\\b\",\n",
    "            \"tertiary\": r\"\\b(Buy|Hold|Sell|Overweight|Overperform|Underperform|Underweight|Neutral)\\b\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"ANALYST\\(S\\) CERTIFICATION\\(S\\)\",\n",
    "                            r\"Analyst\\(s\\) Certification\\(s\\)\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]Expert Sans (Extra Bold)?(Regular)?(Regular,Bold)?\", \"font_size\": 9.0},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Expert Sans (Extra Bold)?(Regular)?\", \"font_size\": 8.04},\n",
    "            {\"font_type\": r\"[A-Z]+[+]SourceSansPro(-Bold)?(-Regular)?\", \"font_size\": 9.00},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 9.01},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 7.58},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 7.52},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 8.52},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 8.75},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 7.60},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 7.11},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 6.52},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 7.02},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 7.03},\n",
    "        ]\n",
    "    },\n",
    "    \"BGC Partners\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target \\(\\$\\) (\\d+(\\.\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"([A-Za-z]+) \\(\\w+,\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Disclosures Appendix\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Tahoma(-Bold)?\", \"font_size\": 7.92},\n",
    "            {\"font_type\": r\"Tahoma(-Bold)?\", \"font_size\": 10.08},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Brean Capital\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"PT: \\$ (\\d+(\\.\\d+)?)\",\n",
    "            \"secondary\": r\"TP: \\$(\\d+(\\.\\d+)?)\",\n",
    "\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(Buy|Hold|Sell|Overweight|Underperform)\\b\"\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Analyst Certification\",r\"Important Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Tahoma(-Bold)?\", \"font_size\": 7.92},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(-Bold)?(-Italic)?\", \"font_size\": 8.00},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(-Bold)?(-Italic)?\", \"font_size\": 9.00},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"BTIG\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"\\$(\\d+(\\.\\d+)?) 12 month target \",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(BUY|HOLD|SELL|OVERWEIGHT|UNDERPERFORM)\\b\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Appendix: Analyst Certification and Other Important Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]Corbel(,Bold)?(,-Italic)?\", \"font_size\": 9.96},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(,Bold)?(,Italic)?\", \"font_size\": 9.96},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(-Bold)?(-Italic)?\", \"font_size\": 10.0},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(,Bold)?(,Italic)?\", \"font_size\": 9.00},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Cascend Securities -Historical-\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price target: \\$(\\d+(\\.\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"Rating: ([A-Za-z]+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Disclosures: \"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(,Bold)?\", \"font_size\": 12.0},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Deutsche Bank\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target \\(USD\\) (\\d+(\\.\\d+)?)\",\n",
    "            \"secondary\": r\"Price target (\\d+(\\.\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(Buy|Hold|Sell|Overweight|Underperform|Underweight|Neutral)\\b\",\n",
    "            #\"secondary\": r\"Rating ([A-Za-z]+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Appendix 1\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]UniversDeutscheBank-Regular\", \"font_size\": 9.0},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"FinTrust Investment Advisors\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Target Price: \\$(\\d+(,\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"Fintrust Rating: ([A-Za-z]+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Important Disclosures:\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Arial(-BoldMT)?\", \"font_size\": 7.92},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Gilford Securities Inc\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"\\, \\$(\\d+(\\.\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"Rated: ([A-Za-z]+)\",\n",
    "            \"secondary\": r\"\\b(BUY|HOLD|SELL|OVERWEIGHT|UNDERPERFORM)\\b\",\n",
    "            \"tertiary\": r\"\\b(Buy|Hold|Sell|Overweight|Underperform|Underweight|Neutral)\\b\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"ANALYST CERTIFICATION\",r\"REQUIRED DISCLOSURES\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\":  r\"Arial(MT)?(-BoldMT)?\", \"font_size\": 10.02},\n",
    "            {\"font_type\":  r\"Arial(MT)?(-BoldMT)?\", \"font_size\": 10.01},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.00},\n",
    "        ]\n",
    "    },\n",
    "    \"Hilliard Lyons\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target (NA|\\$(\\d+(\\.\\d+)?))\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"-- NYSE\\s+[–\\-—]+\\s+([A-Za-z]+)\\s+[–\\-—]+\",\n",
    "            \"secondary\":r\"NYSE\\s+[–\\-—]+\\s+([A-Za-z\\- ]+?)(?=\\s*[-–—]\\d)\"\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Analyst Certification\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Verdana(-Bold)?\", \"font_size\": 9.00},\n",
    "            {\"font_type\":r\"TimesNewRomanPS(-BoldMT)?\", \"font_size\": 10.98},\n",
    "            {\"font_type\":r\"Times(-Bold)?\", \"font_size\": 10.98},\n",
    "            ]\n",
    "    },\n",
    "    \"IBI Investment House\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price target: \\$(\\d+(,\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"Recommendation: ([A-Za-z]+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Tahoma(-Bold)?\", \"font_size\": 7.92},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"IFS Securities\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target: \\$(\\d+(,\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"(Buy|Hold|Sell|Overweight|Underperform|Outperform)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Important Investor Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Arial(-BoldMT)?\", \"font_size\": 11.04},\n",
    "            {\"font_type\":r\"TimesNewRomanPS(MT)?(-BoldMT)?\", \"font_size\": 11.04},\n",
    "        ]\n",
    "    },\n",
    "    \"JP Morgan\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target: \\$(\\d+(\\.\\d+)?)\",\n",
    "            \"secondary\": r\"Price Target \\([A-Za-z0-9\\-]+\\): \\$(\\d+(\\.\\d+)?)\"\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(Buy|Hold|Sell|Overweight|Underperform|Underweight|Neutral)\\b\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Analyst Certification:\",\"Important Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]TimesNewRoman(,Bold)?(,Italic)?\", \"font_size\": 9.60},\n",
    "            {\"font_type\": r\"[A-Z]+[+]TimesNewRoman(,Bold)?(,Italic)?\", \"font_size\": 10.08},\n",
    "            {\"font_type\": r\"[A-Z]+[+]TimesNewRomanPS(MT)?(-BoldMT)(-ItalicMT)?\", \"font_size\": 11.04},\n",
    "            {\"font_type\": r\"[A-Z]+[+]TimesNewRomanPS(MT)?(-BoldMT)?(-ItalicMT)?\", \"font_size\": 10.00},\n",
    "            {\"font_type\": r\"[A-Z]+[+]TimesNewRoman(,Bold)?(,Italic)?\", \"font_size\": 10.56},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Mizuho Securities\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target \\$(\\d+(\\.\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"Rating ([A-Za-z]+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"IMPORTANT DISCLOSURES\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Tahoma(-Bold)?\", \"font_size\": 7.92},\n",
    "            {\"font_type\": r\"Times-Roman(-Bold)?(-Italic)?(-BoldItalic)?\", \"font_size\": 10.50},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Needham\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Price Target: \\$(\\d+(\\.\\d+)?)\",\n",
    "            \"secondary\": r\"PRICE TARGET: \\$(\\d+(\\.\\d+)?)\",\n",
    "            \"tertiary\": r\"Price Target \\$(\\d+(\\.\\d+)?)\",\n",
    "\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(BUY|HOLD|SELL|OVERWEIGHT|UNDERPERFORM)\\b\",\n",
    "            \"secondary\": r\"Rating (\\w+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Analyst Certification\"\n",
    "                            r\"ANALYST CERTIFICATION\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]Cambria(-Bold)?(-Regular)?\", \"font_size\": 10.0},\n",
    "            {\"font_type\": r\"[A-Z]+[+]KeplerStd(-Bold)?\", \"font_size\": 9.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Phillip Securities\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"TARGET PRICE USD (\\d+(\\.\\d+)?)\",\n",
    "            \"secondary\": r\"U\\s?S\\s?D\\s?(\\d+(?:\\s?\\.\\s?\\d+)?)\\s?T\\s?A\\s?R\\s?G\\s?E\\s?T\\s?P\\s?R\\s?I\\s?C\\s?E\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\b(BUY|HOLD|SELL|OVERWEIGHT|UNDERPERFORM)\\b\",\n",
    "            \"secondary\": r\"\\b(B U Y|H O L D|S E L L|O V E R W E I G H T|U N D E R P E R F O R M| N E U T R A L | O U T P E R F O R M)\\b\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Contact Information\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(-Bold)?\", \"font_size\": 9.96},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(-Bold)?\", \"font_size\": 10.0},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Calibri(-Bold)?\", \"font_size\": 9.99},\n",
    "        ]\n",
    "    },\n",
    "    \"Pivotal Research Group\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"Target Price: \\$(\\d+(,\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"RATING: ([A-Za-z]+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Appendix: Important Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]Helvetica(-Bold)?\", \"font_size\": 9.96},\n",
    "            {\"font_type\": r\"Arial(MT)?(-BoldMT)?\", \"font_size\": 8.04},\n",
    "            {\"font_type\": r\"Arial(MT)?(-BoldMT)?\", \"font_size\": 8.03},\n",
    "            {\"font_type\": r\"Arial(MT)?(-BoldMT)?\", \"font_size\": 9.00},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Arial\", \"font_size\": 9.00},\n",
    "        ]\n",
    "    },\n",
    "    \"Spartan Capital Securities LLC\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"T \\$(\\d+(\\.\\d+)?)\",\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"([A-Za-z]+)\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Important Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"Tahoma(-Bold)?\", \"font_size\": 7.92},\n",
    "            {\"font_type\": \"Not Available\", \"font_size\": 10.0},\n",
    "        ]\n",
    "    },\n",
    "    \"Wells Fargo\": {\n",
    "        \"price_patterns\": {\n",
    "            \"primary\": r\"\\/Price Target: \\$(\\d+(\\.\\d+)?)\",\n",
    "            \"secondary\": r\"Price Target\\/Prior: \\$(\\d+(\\.\\d+)?)\",\n",
    "            #\"tertiary\": r\"\\/\\$(\\d+(\\.\\d+)?)\"\n",
    "        },\n",
    "        \"rating_patterns\": {\n",
    "            \"primary\": r\"\\/\\b(Buy|Hold|Sell|Overweight|Underperform|Underweight|Neutral)\\b\",\n",
    "            \"secondary\": r\"Rating (\\w+)\",\n",
    "            \"tertiary\": r\"([A-Za-z]+)/\\$\",\n",
    "        },\n",
    "        \"ending_patterns\": [r\"Required Disclosures\"],\n",
    "        \"font_patterns\": [\n",
    "            {\"font_type\": r\"[A-Z]+[+]WellsFargoSans(-Light)?(,-SemiBold)?\", \"font_size\": 9.00},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Verdana(-Bold)?\", \"font_size\": 8.04},\n",
    "            {\"font_type\": r\"[A-Z]+[+]Verdana(-Bold)?\", \"font_size\": 9.88},\n",
    "            {\"font_type\": r\"[A-Z]+[+]DejaVuSans(-Bold)?\", \"font_size\": 9.01}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validity(paragraph):\n",
    "    # Parse the paragraph\n",
    "    paragraph = re.sub(r\"\\s+\", \" \", paragraph).strip()\n",
    "    doc = nlp(paragraph)\n",
    "        \n",
    "    for sent in doc.sents:\n",
    "        has_verb = False\n",
    "        has_subject = False\n",
    "        \n",
    "        for token in sent:\n",
    "            # Check for a verb\n",
    "            if token.pos_ in {\"VERB\", \"AUX\"}:\n",
    "                has_verb = True\n",
    "            # Check for a subject\n",
    "            if token.dep_ in {\"nsubj\", \"nsubjpass\"}:\n",
    "                has_subject = True\n",
    "        \n",
    "        # If both a verb and a subject are found, the sentence is valid\n",
    "        if has_verb and has_subject:\n",
    "            return True\n",
    "        \n",
    "        # At least one word with 5+ letters and all upper case\n",
    "        if re.search(r\"[A-Z]{5,}\", paragraph):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_valid_paragraphs(paragraphs):\n",
    "    valid_paragraphs = []\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        if check_validity(paragraph):\n",
    "            valid_paragraphs.append(paragraph)\n",
    "    return valid_paragraphs\n",
    "\n",
    "# Function to check if a word ends a sentence\n",
    "def is_sentence_end(word):\n",
    "    text = word[\"text\"]\n",
    "    next_text = word.get(\"next_text\", \"\")\n",
    "\n",
    "    # Sentences definitely end with ! or ?, for . has to be checked further\n",
    "    if text.endswith(\".\") or text.endswith(\"!\") or text.endswith(\"?\"):\n",
    "        # Ensure it's not part of a decimal number\n",
    "        if next_text:\n",
    "            if text.replace(\".\", \"\").isdigit() and next_text.isdigit():\n",
    "                return False\n",
    "            # Check if the next word starts with an uppercase letter (for \".\")\n",
    "            if text.endswith(\".\") and next_text and not next_text.istitle():\n",
    "                return False\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_text_with_format(page, provider, page_number,url_date):\n",
    "\n",
    "    if isinstance(url_date, datetime):\n",
    "        url_date = url_date.date()\n",
    "\n",
    "    date = None\n",
    "\n",
    "    # Access patterns\n",
    "    provider_patterns = patterns[provider]\n",
    "    price_patterns = provider_patterns[\"price_patterns\"]\n",
    "    rating_patterns = provider_patterns[\"rating_patterns\"]\n",
    "    ending_patterns = provider_patterns[\"ending_patterns\"]\n",
    "    font_patterns = provider_patterns[\"font_patterns\"]\n",
    "\n",
    "    # Extract words with font and size details\n",
    "    words = page.extract_words(extra_attrs=[\"fontname\", \"size\"])\n",
    "\n",
    "    # Handle empty words\n",
    "    if not words:\n",
    "        return [], False, None, None, date\n",
    "\n",
    "    # Round text sizes to 2 decimal places -> for calculation\n",
    "    for word in words:\n",
    "        if \"size\" in word and word[\"size\"] is not None:\n",
    "            word[\"size\"] = round(word[\"size\"], 2)\n",
    "\n",
    "    # Sort words by vertical and horizontal position\n",
    "    words.sort(key=lambda w: (w[\"top\"], w[\"x0\"]))\n",
    "\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    current_top = None\n",
    "    sentence_ended = False  # Track if the last processed sentence has ended -> relevant for paragraph closing/opening\n",
    "    lookahead_buffer = []\n",
    "    rating = None\n",
    "    price = None\n",
    "    extracted_date = None\n",
    "\n",
    "    # Add next word context for sentence-ending logic\n",
    "    for i in range(len(words) - 1):\n",
    "        words[i][\"next_text\"] = words[i + 1][\"text\"]\n",
    "    words[-1][\"next_text\"] = None \n",
    "\n",
    "\n",
    "    # Check all words of the document\n",
    "    for word in words:\n",
    "        \n",
    "        next_text = word.get(\"next_text\", \"\")\n",
    "\n",
    "        # Build lookahead buffer\n",
    "        lookahead_buffer.append(word[\"text\"])\n",
    "        if len(lookahead_buffer) > 35:\n",
    "            lookahead_buffer.pop(0)\n",
    "        buffer_text = \" \".join(lookahead_buffer)\n",
    "\n",
    "        # Extract rating or price (only for page 1) -> more efficient, because rating etc. not relevant\n",
    "        if page_number == 1:\n",
    "            # Extract rating\n",
    "            if not rating:\n",
    "                for pattern_key in [\"primary\", \"secondary\", \"tertiary\"]:\n",
    "                    pattern = rating_patterns.get(pattern_key)\n",
    "                    if pattern:\n",
    "                        rating_match = re.search(pattern, buffer_text)\n",
    "                        if rating_match:\n",
    "                            rating = rating_match.group(1)\n",
    "                            break\n",
    "\n",
    "            # Extract price\n",
    "            if not price:\n",
    "                for pattern_key in [\"primary\", \"secondary\", \"tertiary\"]:\n",
    "                    pattern = price_patterns.get(pattern_key)\n",
    "                    if pattern:\n",
    "                        price_match = re.search(pattern, buffer_text)\n",
    "                        if price_match:\n",
    "                            price = price_match.group(1)\n",
    "                            break\n",
    "\n",
    "            # Look for date entities in the text\n",
    "            if len(buffer_text.split()) > 30:\n",
    "                if date is None:\n",
    "                    sequence = nlp(buffer_text)\n",
    "                    for ent in sequence.ents:\n",
    "                        if ent.label_ == \"DATE\":\n",
    "                            try:\n",
    "                                candidate_date = parse(ent.text, fuzzy=True).date()\n",
    "                        \n",
    "                                # Check if date is date is valid\n",
    "                                if datetime.min.date() <= candidate_date <= datetime.max.date():\n",
    "                                    extracted_date = candidate_date\n",
    "                                    break  # Stop if date is found\n",
    "\n",
    "                            except (ValueError, OverflowError):\n",
    "                                continue  # Skip invalid dates\n",
    "                    \n",
    "                    # Calculate the difference\n",
    "                    date_difference = 0\n",
    "                    if extracted_date:\n",
    "                        date_difference = (url_date - extracted_date).days\n",
    "                        \n",
    "                    # Check the conditions (should only be taken if within 10 days)\n",
    "                    if extracted_date and (0 <= date_difference <= 10):\n",
    "                        date = extracted_date\n",
    "                        \n",
    "        # Check for ending pattern\n",
    "        for ending_pattern in ending_patterns:\n",
    "            if re.search(ending_pattern, buffer_text):\n",
    "                return filter_valid_paragraphs(paragraphs), True, rating, price, date\n",
    "        \n",
    "        # Match word against font patterns, include only if both font and type are matched\n",
    "        is_font_matched = False\n",
    "        for font_pattern in font_patterns:\n",
    "            font_type = font_pattern[\"font_type\"]\n",
    "            font_size = font_pattern[\"font_size\"]\n",
    "            if re.match(font_type, word[\"fontname\"]) and word[\"size\"] == font_size:\n",
    "                is_font_matched = True\n",
    "                break\n",
    "\n",
    "        if not is_font_matched:\n",
    "            continue\n",
    "\n",
    "        \"\"\" # Check if the word ends a sentence\n",
    "        if is_sentence_end(word):\n",
    "            sentence_ended = True\"\"\"\n",
    "\n",
    "        # Check if we need to start a new paragraph\n",
    "        if current_top is not None and abs(word[\"top\"] - current_top) >= 16:\n",
    "            if word['text'] and word['text'][0].islower():\n",
    "                current_paragraph.append(word[\"text\"])\n",
    "            else:\n",
    "                paragraphs.append(\" \".join(current_paragraph))\n",
    "                current_paragraph = [word[\"text\"]]\n",
    "        else:\n",
    "            # Continue the current paragraph\n",
    "            current_paragraph.append(word[\"text\"])\n",
    "\n",
    "\n",
    "        current_top = word[\"top\"]\n",
    "\n",
    "    #Add paragraph to list of paragraphs\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(\" \".join(current_paragraph))\n",
    "\n",
    "    return filter_valid_paragraphs(paragraphs), False, rating, price, date\n",
    "\n",
    "\n",
    "def extract_metadata(filename, ticker_map):\n",
    "    \n",
    "    # Extract the date (first 8 digits in the filename)\n",
    "    date_match = re.match(r\"(\\d{8})\", filename)\n",
    "    if not date_match:\n",
    "        return None, None, None, None, None\n",
    "    date_str = date_match.group(1)\n",
    "    date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "\n",
    "    #print(f\"fileName: {filename}\")\n",
    "    #print(f\"date: {date}\")\n",
    "\n",
    "    # Look for the ticker in the filename\n",
    "    for ticker in ticker_map.keys():\n",
    "        ticker_pattern = f\"_{ticker}_\"  # Ensure ticker is surrounded by underscores\n",
    "        if ticker_pattern in filename:\n",
    "            # Extract the portion between date and ticker as the provider\n",
    "            provider_section = filename.split(f\"{date_str}_\")[1].split(f\"_{ticker}_\")[0]\n",
    "            provider = provider_section.replace('_', ' ')  # Replace underscores with spaces\n",
    "            # Get company name and industry from the ticker_map\n",
    "            company_name = ticker_map[ticker]['Company Name']\n",
    "            industry = ticker_map[ticker]['Industry']\n",
    "            return date, provider, ticker, company_name, industry\n",
    "\n",
    "    # If no ticker is found, return None for ticker-related fields\n",
    "    return date, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname E identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "# Define function to process all PDFs in the directory and store data in DataFrame\n",
    "def extract_text_from_all_pdfs_to_dataframe(directory_path, ticker_map):\n",
    "    data = []\n",
    "    id_counter = 1  # Initialize an ID counter\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):  # Process only PDF files\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            # Extract metadata from filename\n",
    "            url_date, provider, ticker, company_name, industry = extract_metadata(filename,ticker_map=ticker_map)\n",
    "            all_paragraphs = []  \n",
    "            first_rating = None\n",
    "            first_price = None\n",
    "            first_date = None\n",
    "            stop_extraction = False\n",
    "\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "                for page_number, page in enumerate(pdf.pages, start=1):\n",
    "                    if stop_extraction:\n",
    "                        break  # Exit the loop if stop_extraction is set\n",
    "            \n",
    "                    # Extract data from the current page\n",
    "                    paragraphs, stop_extraction, rating, price,new_date = extract_text_with_format(page, provider=provider,page_number=page_number,url_date=url_date)\n",
    "                    \n",
    "                    # Append paragraphs from the current page\n",
    "                    all_paragraphs.extend(paragraphs)\n",
    "\n",
    "                    # Capture the first non-None rating and price\n",
    "                    if rating is not None and first_rating is None:\n",
    "                        first_rating = rating\n",
    "                    if price is not None and first_price is None:\n",
    "                        first_price = price\n",
    "\n",
    "                    if new_date is not None and first_date is None:\n",
    "                        first_date = new_date\n",
    "                        \n",
    "            if first_date is None:\n",
    "                first_date = url_date.date()\n",
    "                        \n",
    "            # Add extracted data to the list\n",
    "            data.append({\n",
    "                \"document_id\": id_counter,  # Unique ID\n",
    "                \"filename\": filename,\n",
    "                \"date\": first_date,\n",
    "                \"provider\": provider,\n",
    "                \"ticker\": ticker,\n",
    "                \"company_name\": company_name,\n",
    "                \"industry\": industry,\n",
    "                \"paragraphs\": all_paragraphs,\n",
    "                \"target_price\":first_price.replace(\" \",\"\") if first_price else None,\n",
    "                \"rating\": first_rating.lower().replace(\" \",\"\") if first_rating else None\n",
    "                })\n",
    "            id_counter += 1  # Increment the ID counter for the next row\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Directory path\n",
    "pdf_directory = \"/Users/oskarroeske/Desktop/Analyst_Reports/Production\"\n",
    "\n",
    "# Run the function and store results in a DataFrame\n",
    "df_reports = extract_text_from_all_pdfs_to_dataframe(pdf_directory, ticker_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>provider</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>target_price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20161018_Needham_META_Facebook-_3Q16_Preview_R...</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>Needham</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta Platforms Inc.</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>[BUY INVESTMENT HIGHLIGHTS: $150.00 We raise o...</td>\n",
       "      <td>None</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20200807_Wells_Fargo_META_FB-_2.5B_Person_Plat...</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta Platforms Inc.</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>[Solid 2Q Beat, E-Commerce Initiatives Remain ...</td>\n",
       "      <td>300</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20200918_Barclays_GM_General_Motors-_Time_to_t...</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>GM</td>\n",
       "      <td>General Motors Co.</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>[CEO Mary Barra earlier today presented at a c...</td>\n",
       "      <td>39.00</td>\n",
       "      <td>overweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20200722_Barclays_BKNG_Booking_Holdings_Inc.-_...</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>BKNG</td>\n",
       "      <td>Booking Holdings Inc</td>\n",
       "      <td>Travel</td>\n",
       "      <td>[OVERWEIGHT Stock Rating Unchanged, POSITIVE I...</td>\n",
       "      <td>None</td>\n",
       "      <td>overweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211104_Deutsche_Bank_X_US_Steel-_3Q21_EBITDA...</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>X</td>\n",
       "      <td>United States Steel</td>\n",
       "      <td>Materials</td>\n",
       "      <td>[3Q21 FCF of $1.3bn, ND down 46% QoQ, boosts S...</td>\n",
       "      <td>50.00</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>919</td>\n",
       "      <td>20150522_Gilford_Securities_Inc_FL_Report_rece...</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>Gilford Securities Inc</td>\n",
       "      <td>FL</td>\n",
       "      <td>Foot Locker</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>[Investment Opinion: Foot Locker continues to ...</td>\n",
       "      <td>None</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>920</td>\n",
       "      <td>20200526_Wells_Fargo_HD_HD-_Q2_Rollover_Falls_...</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>HD</td>\n",
       "      <td>Home Depot Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>[With Q1 strength continuing into May, seeing ...</td>\n",
       "      <td>270</td>\n",
       "      <td>overweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>921</td>\n",
       "      <td>20220125_Deutsche_Bank_WFC_Wells_Fargo-_More_C...</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>WFC</td>\n",
       "      <td>Wells Fargo &amp; Co.</td>\n",
       "      <td>Financials</td>\n",
       "      <td>[WFC posted a solid and mostly in-line 4Q (det...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>922</td>\n",
       "      <td>20200212_Barclays_GM_General_Motors-_Waiting_p...</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>GM</td>\n",
       "      <td>General Motors Co.</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>[OVERWEIGHT Stock Rating Unchanged, NEUTRAL In...</td>\n",
       "      <td>None</td>\n",
       "      <td>overweight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>923</td>\n",
       "      <td>20140122_Pivotal_Research_Group_GOOGL_GOOG-_Gr...</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>Pivotal Research Group</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>[GOOGLE (GOOG), RATING: HOLD, 200 Park Ave., W...</td>\n",
       "      <td>1070</td>\n",
       "      <td>hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id                                           filename  \\\n",
       "0              1  20161018_Needham_META_Facebook-_3Q16_Preview_R...   \n",
       "1              2  20200807_Wells_Fargo_META_FB-_2.5B_Person_Plat...   \n",
       "2              3  20200918_Barclays_GM_General_Motors-_Time_to_t...   \n",
       "3              4  20200722_Barclays_BKNG_Booking_Holdings_Inc.-_...   \n",
       "4              5  20211104_Deutsche_Bank_X_US_Steel-_3Q21_EBITDA...   \n",
       "..           ...                                                ...   \n",
       "918          919  20150522_Gilford_Securities_Inc_FL_Report_rece...   \n",
       "919          920  20200526_Wells_Fargo_HD_HD-_Q2_Rollover_Falls_...   \n",
       "920          921  20220125_Deutsche_Bank_WFC_Wells_Fargo-_More_C...   \n",
       "921          922  20200212_Barclays_GM_General_Motors-_Waiting_p...   \n",
       "922          923  20140122_Pivotal_Research_Group_GOOGL_GOOG-_Gr...   \n",
       "\n",
       "           date                provider ticker          company_name  \\\n",
       "0    2016-10-11                 Needham   META   Meta Platforms Inc.   \n",
       "1    2020-07-31             Wells Fargo   META   Meta Platforms Inc.   \n",
       "2    2020-09-14                Barclays     GM    General Motors Co.   \n",
       "3    2020-07-16                Barclays   BKNG  Booking Holdings Inc   \n",
       "4    2021-10-28           Deutsche Bank      X   United States Steel   \n",
       "..          ...                     ...    ...                   ...   \n",
       "918  2015-05-22  Gilford Securities Inc     FL           Foot Locker   \n",
       "919  2020-05-19             Wells Fargo     HD       Home Depot Inc.   \n",
       "920  2022-01-17           Deutsche Bank    WFC     Wells Fargo & Co.   \n",
       "921  2020-02-06                Barclays     GM    General Motors Co.   \n",
       "922  2014-01-21  Pivotal Research Group  GOOGL         Alphabet Inc.   \n",
       "\n",
       "                   industry  \\\n",
       "0    Communication Services   \n",
       "1    Communication Services   \n",
       "2                Automobile   \n",
       "3                    Travel   \n",
       "4                 Materials   \n",
       "..                      ...   \n",
       "918                Clothing   \n",
       "919  Consumer Discretionary   \n",
       "920              Financials   \n",
       "921              Automobile   \n",
       "922  Communication Services   \n",
       "\n",
       "                                            paragraphs target_price  \\\n",
       "0    [BUY INVESTMENT HIGHLIGHTS: $150.00 We raise o...         None   \n",
       "1    [Solid 2Q Beat, E-Commerce Initiatives Remain ...          300   \n",
       "2    [CEO Mary Barra earlier today presented at a c...        39.00   \n",
       "3    [OVERWEIGHT Stock Rating Unchanged, POSITIVE I...         None   \n",
       "4    [3Q21 FCF of $1.3bn, ND down 46% QoQ, boosts S...        50.00   \n",
       "..                                                 ...          ...   \n",
       "918  [Investment Opinion: Foot Locker continues to ...         None   \n",
       "919  [With Q1 strength continuing into May, seeing ...          270   \n",
       "920  [WFC posted a solid and mostly in-line 4Q (det...        55.00   \n",
       "921  [OVERWEIGHT Stock Rating Unchanged, NEUTRAL In...         None   \n",
       "922  [GOOGLE (GOOG), RATING: HOLD, 200 Park Ave., W...         1070   \n",
       "\n",
       "         rating  \n",
       "0           buy  \n",
       "1             v  \n",
       "2    overweight  \n",
       "3    overweight  \n",
       "4           buy  \n",
       "..          ...  \n",
       "918         buy  \n",
       "919  overweight  \n",
       "920         buy  \n",
       "921  overweight  \n",
       "922        hold  \n",
       "\n",
       "[923 rows x 10 columns]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_paragraph(paragraph):\n",
    "    # Remove email addresses\n",
    "    paragraph = re.sub(r\"\\S+@\\S+\", \"\", paragraph)\n",
    "    \n",
    "    # Remove phone numbers\n",
    "    paragraph = re.sub(r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}(?:\\s?(?:ext|x|ext.)\\s?\\d{1,5})?\\b\", \"\", paragraph)\n",
    "    \n",
    "    # Remove URLs\n",
    "    paragraph = re.sub(r\"http\\S+|www\\S+\", \"\", paragraph)\n",
    "    \n",
    "    # Remove special characters (keep alphanumerics, spaces, and common punctuation)\n",
    "    paragraph = re.sub(r\"[^/\\w\\s,.&!?%$:-]\", \"\", paragraph)\n",
    "    \n",
    "    # Remove multiple spaces or newlines\n",
    "    paragraph = re.sub(r\"\\s+\", \" \", paragraph).strip()\n",
    "\n",
    "    #Check Headers that are in line with the other texts\n",
    "    paragraph = re.sub(r\"\\b(?:[A-Z]{2,}\\s+){2,}[A-Z]{2,}\\b\", \"\", paragraph)\n",
    "    \n",
    "    # Remove short paragraphs (fewer than 6 words) -> probably not an actual paragraph\n",
    "    if len(paragraph.split()) < 6:\n",
    "        return None\n",
    "    \n",
    "    return paragraph\n",
    "\n",
    "# Apply cleaning function\n",
    "df_reports['paragraphs'] = df_reports['paragraphs'].apply(\n",
    "    lambda paragraphs: [clean_paragraph(p) for p in paragraphs if clean_paragraph(p)]\n",
    ")\n",
    "\n",
    "# Drop rows where the `paragraphs` column is empty after cleaning\n",
    "df_reports = df_reports[df_reports['paragraphs'].str.len() > 0]\n",
    "\n",
    "df_reports[\"rating\"] = df_reports[\"rating\"].astype(str).apply(lambda x: x.lower() if x != \"nan\" else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Date and Price for Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and ensure 'Date' is in datetime format\n",
    "df_performance_data = pd.read_csv(\"performance_data.csv\")\n",
    "\n",
    "# Convert 'Date' column to datetime and set it as index (with timezone awareness)\n",
    "df_performance_data['Date'] = pd.to_datetime(df_performance_data['Date'], utc=True)\n",
    "df_performance_data = df_performance_data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saved_reports = df_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_prices(ticker, start_date, end_date=None):\n",
    "    try:\n",
    "        # Ensure start_date and end_date are in the same timezone (UTC)\n",
    "        start_date = pd.to_datetime(start_date, utc=True)\n",
    "        if end_date is not None:\n",
    "            end_date = pd.to_datetime(end_date, utc=True)\n",
    "        else:\n",
    "            end_date = start_date  # If no end_date, use start_date for a single day\n",
    "\n",
    "        # Filter the data for the ticker and date range\n",
    "        filtered_data = df_performance_data.loc[\n",
    "            (df_performance_data.index >= start_date) & \n",
    "            (df_performance_data.index <= end_date), ticker]\n",
    "\n",
    "        if not filtered_data.empty:\n",
    "            # Return the maximum price within the filtered date range\n",
    "            max_price = filtered_data.max()\n",
    "            min_price = filtered_data.min()\n",
    "            return round(float(max_price),2), round(float(min_price),2)\n",
    "        else:\n",
    "            # If no data available in the range, find the next available date using asof())\n",
    "            next_available_data = df_performance_data[ticker].asof(start_date)\n",
    "            if next_available_data is not None:\n",
    "                return round(float(next_available_data),2), round(float(next_available_data),2)\n",
    "            else:\n",
    "                return round(float('nan')), round(float('nan'))  # Return NaN for missing data\n",
    "\n",
    "    except KeyError:\n",
    "        return float('nan'), float('nan')  # Return NaN for missing data\n",
    "    except Exception as e:\n",
    "        return float('nan'), float('nan')  # Return NaN for missing data\n",
    "\n",
    "def calculate_prices(row):\n",
    "    short_name = row['ticker']\n",
    "    base_date = pd.to_datetime(row['date'], utc=True)\n",
    "\n",
    "    # Calculate prices\n",
    "    row['start price'] = get_stock_prices(short_name, base_date)[0]\n",
    "    row['one day after'] = get_stock_prices(short_name, base_date + pd.DateOffset(days=1))[0]\n",
    "    row['max price after 3 months'], row[\"min price after 3 months\"] = get_stock_prices(\n",
    "        short_name, base_date, base_date + pd.DateOffset(months=3)\n",
    "    )\n",
    "    row['max price after 6 months'], row['min price after 6 months'] = get_stock_prices(\n",
    "        short_name, base_date + pd.DateOffset(months=3), base_date + pd.DateOffset(months=6)\n",
    "    )\n",
    "    row['max price after 9 months'], row['min price after 9 months'] = get_stock_prices(\n",
    "        short_name, base_date + pd.DateOffset(months=6), base_date + pd.DateOffset(months=9)\n",
    "    )\n",
    "    row['max price after 12 months'], row['min price after 12 months'] = get_stock_prices(\n",
    "        short_name, base_date + pd.DateOffset(months=9), base_date + pd.DateOffset(months=12)\n",
    "    )\n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "df_saved_reports = df_saved_reports.apply(calculate_prices, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust target price for companies that had a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saved_reports[\"target_price\"] = (\n",
    "    df_saved_reports[\"target_price\"]\n",
    "    .replace(\",\", \"\", regex=True)  # Remove commas\n",
    "    .pipe(pd.to_numeric, errors=\"coerce\")  # Convert to float; invalid values become NaN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>provider</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>target_price</th>\n",
       "      <th>rating</th>\n",
       "      <th>...</th>\n",
       "      <th>one day after</th>\n",
       "      <th>max price after 3 months</th>\n",
       "      <th>min price after 3 months</th>\n",
       "      <th>max price after 6 months</th>\n",
       "      <th>min price after 6 months</th>\n",
       "      <th>max price after 9 months</th>\n",
       "      <th>min price after 9 months</th>\n",
       "      <th>max price after 12 months</th>\n",
       "      <th>min price after 12 months</th>\n",
       "      <th>adjusted_target_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20161018_Needham_META_Facebook-_3Q16_Preview_R...</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>Needham</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta Platforms Inc.</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>[: $150.00 We raise our estimates for 3Q16 as ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buy</td>\n",
       "      <td>...</td>\n",
       "      <td>128.66</td>\n",
       "      <td>132.88</td>\n",
       "      <td>114.70</td>\n",
       "      <td>142.22</td>\n",
       "      <td>125.71</td>\n",
       "      <td>154.80</td>\n",
       "      <td>138.97</td>\n",
       "      <td>172.99</td>\n",
       "      <td>154.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20200807_Wells_Fargo_META_FB-_2.5B_Person_Plat...</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta Platforms Inc.</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>[Solid 2Q Beat, E-Commerce Initiatives Remain ...</td>\n",
       "      <td>300.0</td>\n",
       "      <td>v</td>\n",
       "      <td>...</td>\n",
       "      <td>252.91</td>\n",
       "      <td>303.00</td>\n",
       "      <td>247.41</td>\n",
       "      <td>293.80</td>\n",
       "      <td>244.90</td>\n",
       "      <td>328.52</td>\n",
       "      <td>253.93</td>\n",
       "      <td>372.16</td>\n",
       "      <td>301.64</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20200918_Barclays_GM_General_Motors-_Time_to_t...</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>GM</td>\n",
       "      <td>General Motors Co.</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>[CEO Mary Barra earlier today presented at a c...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>overweight</td>\n",
       "      <td>...</td>\n",
       "      <td>30.85</td>\n",
       "      <td>45.39</td>\n",
       "      <td>28.08</td>\n",
       "      <td>57.90</td>\n",
       "      <td>39.58</td>\n",
       "      <td>62.45</td>\n",
       "      <td>52.52</td>\n",
       "      <td>60.34</td>\n",
       "      <td>47.07</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20200722_Barclays_BKNG_Booking_Holdings_Inc.-_...</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>BKNG</td>\n",
       "      <td>Booking Holdings Inc</td>\n",
       "      <td>Travel</td>\n",
       "      <td>[POSITIVE Industry View Unchanged The Key Take...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overweight</td>\n",
       "      <td>...</td>\n",
       "      <td>1719.81</td>\n",
       "      <td>1934.80</td>\n",
       "      <td>1626.76</td>\n",
       "      <td>2265.24</td>\n",
       "      <td>1592.67</td>\n",
       "      <td>2459.20</td>\n",
       "      <td>1872.61</td>\n",
       "      <td>2487.20</td>\n",
       "      <td>2129.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211104_Deutsche_Bank_X_US_Steel-_3Q21_EBITDA...</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>X</td>\n",
       "      <td>United States Steel</td>\n",
       "      <td>Materials</td>\n",
       "      <td>[3Q21 FCF of $1.3bn, ND down 46% QoQ, boosts S...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>buy</td>\n",
       "      <td>...</td>\n",
       "      <td>25.78</td>\n",
       "      <td>26.31</td>\n",
       "      <td>18.20</td>\n",
       "      <td>37.72</td>\n",
       "      <td>19.13</td>\n",
       "      <td>31.62</td>\n",
       "      <td>16.73</td>\n",
       "      <td>25.45</td>\n",
       "      <td>17.85</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>919</td>\n",
       "      <td>20150522_Gilford_Securities_Inc_FL_Report_rece...</td>\n",
       "      <td>2015-05-22</td>\n",
       "      <td>Gilford Securities Inc</td>\n",
       "      <td>FL</td>\n",
       "      <td>Foot Locker</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>[Investment Opinion: Foot Locker continues to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buy</td>\n",
       "      <td>...</td>\n",
       "      <td>48.99</td>\n",
       "      <td>57.42</td>\n",
       "      <td>47.86</td>\n",
       "      <td>58.69</td>\n",
       "      <td>45.12</td>\n",
       "      <td>53.97</td>\n",
       "      <td>47.34</td>\n",
       "      <td>52.49</td>\n",
       "      <td>42.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>920</td>\n",
       "      <td>20200526_Wells_Fargo_HD_HD-_Q2_Rollover_Falls_...</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>HD</td>\n",
       "      <td>Home Depot Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>[With Q1 strength continuing into May, seeing ...</td>\n",
       "      <td>270.0</td>\n",
       "      <td>overweight</td>\n",
       "      <td>...</td>\n",
       "      <td>213.68</td>\n",
       "      <td>260.13</td>\n",
       "      <td>213.60</td>\n",
       "      <td>263.46</td>\n",
       "      <td>241.05</td>\n",
       "      <td>260.04</td>\n",
       "      <td>238.74</td>\n",
       "      <td>313.11</td>\n",
       "      <td>228.89</td>\n",
       "      <td>270.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>921</td>\n",
       "      <td>20220125_Deutsche_Bank_WFC_Wells_Fargo-_More_C...</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>WFC</td>\n",
       "      <td>Wells Fargo &amp; Co.</td>\n",
       "      <td>Financials</td>\n",
       "      <td>[WFC posted a solid and mostly in-line 4Q deta...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>buy</td>\n",
       "      <td>...</td>\n",
       "      <td>52.33</td>\n",
       "      <td>54.76</td>\n",
       "      <td>42.47</td>\n",
       "      <td>45.11</td>\n",
       "      <td>34.89</td>\n",
       "      <td>43.31</td>\n",
       "      <td>37.55</td>\n",
       "      <td>45.30</td>\n",
       "      <td>38.43</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>922</td>\n",
       "      <td>20200212_Barclays_GM_General_Motors-_Waiting_p...</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>GM</td>\n",
       "      <td>General Motors Co.</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>[NEUTRAL Industry View Solid execution and ong...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overweight</td>\n",
       "      <td>...</td>\n",
       "      <td>32.46</td>\n",
       "      <td>34.26</td>\n",
       "      <td>16.41</td>\n",
       "      <td>29.97</td>\n",
       "      <td>20.97</td>\n",
       "      <td>36.61</td>\n",
       "      <td>26.01</td>\n",
       "      <td>54.58</td>\n",
       "      <td>36.61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>923</td>\n",
       "      <td>20140122_Pivotal_Research_Group_GOOGL_GOOG-_Gr...</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>Pivotal Research Group</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>[200 Park Ave., West Mezzanine New York, NY 10...</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>hold</td>\n",
       "      <td>...</td>\n",
       "      <td>29.08</td>\n",
       "      <td>30.46</td>\n",
       "      <td>26.82</td>\n",
       "      <td>30.18</td>\n",
       "      <td>25.84</td>\n",
       "      <td>30.20</td>\n",
       "      <td>26.08</td>\n",
       "      <td>28.32</td>\n",
       "      <td>24.79</td>\n",
       "      <td>26.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id                                           filename  \\\n",
       "0              1  20161018_Needham_META_Facebook-_3Q16_Preview_R...   \n",
       "1              2  20200807_Wells_Fargo_META_FB-_2.5B_Person_Plat...   \n",
       "2              3  20200918_Barclays_GM_General_Motors-_Time_to_t...   \n",
       "3              4  20200722_Barclays_BKNG_Booking_Holdings_Inc.-_...   \n",
       "4              5  20211104_Deutsche_Bank_X_US_Steel-_3Q21_EBITDA...   \n",
       "..           ...                                                ...   \n",
       "918          919  20150522_Gilford_Securities_Inc_FL_Report_rece...   \n",
       "919          920  20200526_Wells_Fargo_HD_HD-_Q2_Rollover_Falls_...   \n",
       "920          921  20220125_Deutsche_Bank_WFC_Wells_Fargo-_More_C...   \n",
       "921          922  20200212_Barclays_GM_General_Motors-_Waiting_p...   \n",
       "922          923  20140122_Pivotal_Research_Group_GOOGL_GOOG-_Gr...   \n",
       "\n",
       "           date                provider ticker          company_name  \\\n",
       "0    2016-10-11                 Needham   META   Meta Platforms Inc.   \n",
       "1    2020-07-31             Wells Fargo   META   Meta Platforms Inc.   \n",
       "2    2020-09-14                Barclays     GM    General Motors Co.   \n",
       "3    2020-07-16                Barclays   BKNG  Booking Holdings Inc   \n",
       "4    2021-10-28           Deutsche Bank      X   United States Steel   \n",
       "..          ...                     ...    ...                   ...   \n",
       "918  2015-05-22  Gilford Securities Inc     FL           Foot Locker   \n",
       "919  2020-05-19             Wells Fargo     HD       Home Depot Inc.   \n",
       "920  2022-01-17           Deutsche Bank    WFC     Wells Fargo & Co.   \n",
       "921  2020-02-06                Barclays     GM    General Motors Co.   \n",
       "922  2014-01-21  Pivotal Research Group  GOOGL         Alphabet Inc.   \n",
       "\n",
       "                   industry  \\\n",
       "0    Communication Services   \n",
       "1    Communication Services   \n",
       "2                Automobile   \n",
       "3                    Travel   \n",
       "4                 Materials   \n",
       "..                      ...   \n",
       "918                Clothing   \n",
       "919  Consumer Discretionary   \n",
       "920              Financials   \n",
       "921              Automobile   \n",
       "922  Communication Services   \n",
       "\n",
       "                                            paragraphs  target_price  \\\n",
       "0    [: $150.00 We raise our estimates for 3Q16 as ...           NaN   \n",
       "1    [Solid 2Q Beat, E-Commerce Initiatives Remain ...         300.0   \n",
       "2    [CEO Mary Barra earlier today presented at a c...          39.0   \n",
       "3    [POSITIVE Industry View Unchanged The Key Take...           NaN   \n",
       "4    [3Q21 FCF of $1.3bn, ND down 46% QoQ, boosts S...          50.0   \n",
       "..                                                 ...           ...   \n",
       "918  [Investment Opinion: Foot Locker continues to ...           NaN   \n",
       "919  [With Q1 strength continuing into May, seeing ...         270.0   \n",
       "920  [WFC posted a solid and mostly in-line 4Q deta...          55.0   \n",
       "921  [NEUTRAL Industry View Solid execution and ong...           NaN   \n",
       "922  [200 Park Ave., West Mezzanine New York, NY 10...        1070.0   \n",
       "\n",
       "         rating  ...  one day after  max price after 3 months  \\\n",
       "0           buy  ...         128.66                    132.88   \n",
       "1             v  ...         252.91                    303.00   \n",
       "2    overweight  ...          30.85                     45.39   \n",
       "3    overweight  ...        1719.81                   1934.80   \n",
       "4           buy  ...          25.78                     26.31   \n",
       "..          ...  ...            ...                       ...   \n",
       "918         buy  ...          48.99                     57.42   \n",
       "919  overweight  ...         213.68                    260.13   \n",
       "920         buy  ...          52.33                     54.76   \n",
       "921  overweight  ...          32.46                     34.26   \n",
       "922        hold  ...          29.08                     30.46   \n",
       "\n",
       "     min price after 3 months  max price after 6 months  \\\n",
       "0                      114.70                    142.22   \n",
       "1                      247.41                    293.80   \n",
       "2                       28.08                     57.90   \n",
       "3                     1626.76                   2265.24   \n",
       "4                       18.20                     37.72   \n",
       "..                        ...                       ...   \n",
       "918                     47.86                     58.69   \n",
       "919                    213.60                    263.46   \n",
       "920                     42.47                     45.11   \n",
       "921                     16.41                     29.97   \n",
       "922                     26.82                     30.18   \n",
       "\n",
       "     min price after 6 months  max price after 9 months  \\\n",
       "0                      125.71                    154.80   \n",
       "1                      244.90                    328.52   \n",
       "2                       39.58                     62.45   \n",
       "3                     1592.67                   2459.20   \n",
       "4                       19.13                     31.62   \n",
       "..                        ...                       ...   \n",
       "918                     45.12                     53.97   \n",
       "919                    241.05                    260.04   \n",
       "920                     34.89                     43.31   \n",
       "921                     20.97                     36.61   \n",
       "922                     25.84                     30.20   \n",
       "\n",
       "     min price after 9 months  max price after 12 months  \\\n",
       "0                      138.97                     172.99   \n",
       "1                      253.93                     372.16   \n",
       "2                       52.52                      60.34   \n",
       "3                     1872.61                    2487.20   \n",
       "4                       16.73                      25.45   \n",
       "..                        ...                        ...   \n",
       "918                     47.34                      52.49   \n",
       "919                    238.74                     313.11   \n",
       "920                     37.55                      45.30   \n",
       "921                     26.01                      54.58   \n",
       "922                     26.08                      28.32   \n",
       "\n",
       "     min price after 12 months  adjusted_target_price  \n",
       "0                       154.80                    NaN  \n",
       "1                       301.64                 300.00  \n",
       "2                        47.07                  39.00  \n",
       "3                      2129.39                    NaN  \n",
       "4                        17.85                  50.00  \n",
       "..                         ...                    ...  \n",
       "918                      42.95                    NaN  \n",
       "919                     228.89                 270.00  \n",
       "920                      38.43                  55.00  \n",
       "921                      36.61                    NaN  \n",
       "922                      24.79                  26.65  \n",
       "\n",
       "[923 rows x 21 columns]"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Example stock splits dictionary (as provided)\n",
    "stock_splits = {\n",
    "    \"AAPL\": [\n",
    "        {\"split_ratio\": 7, \"ex_date\": \"2014-06-09\"},\n",
    "        {\"split_ratio\": 4, \"ex_date\": \"2020-08-31\"}\n",
    "    ],\n",
    "    \"AMZN\": [\n",
    "        {\"split_ratio\": 20, \"ex_date\": \"2022-06-06\"}\n",
    "    ],\n",
    "    \"TSLA\": [\n",
    "        {\"split_ratio\": 5, \"ex_date\": \"2020-08-31\"},\n",
    "        {\"split_ratio\": 3, \"ex_date\": \"2022-08-25\"}\n",
    "    ],\n",
    "    \"GOOGL\": [\n",
    "        {\"split_ratio\": 20, \"ex_date\": \"2022-07-18\"},\n",
    "        {\"split_ratio\": 1.0027455, \"ex_date\": \"2015-04-27\"},\n",
    "        {\"split_ratio\": 2.002, \"ex_date\": \"2014-03-27\"},\n",
    "    ],\n",
    "    \"NVDA\": [\n",
    "        {\"split_ratio\": 10, \"ex_date\": \"2024-06-10\"},\n",
    "        {\"split_ratio\": 4, \"ex_date\": \"2021-07-20\"}\n",
    "    ],\n",
    "    \"NKE\": [\n",
    "        {\"split_ratio\": 2, \"ex_date\": \"2015-12-24\"}\n",
    "    ],\n",
    "    \"V\": [\n",
    "        {\"split_ratio\": 4, \"ex_date\": \"2015-03-19\"}\n",
    "    ],\n",
    "    \"MA\": [\n",
    "        {\"split_ratio\": 10, \"ex_date\": \"2014-01-22\"}\n",
    "    ],\n",
    "    \"WMT\": [\n",
    "        {\"split_ratio\": 3, \"ex_date\": \"2024-02-26\"}\n",
    "    ],\n",
    "    \"SBUX\": [\n",
    "        {\"split_ratio\": 2, \"ex_date\": \"2015-04-09\"}\n",
    "    ],\n",
    "    \"UNP\": [\n",
    "        {\"split_ratio\": 2, \"ex_date\": \"2014-06-09\"}\n",
    "    ],\n",
    "    \"UAA\": [\n",
    "        {\"split_ratio\": 2, \"ex_date\": \"2014-04-15\"}\n",
    "    ],\n",
    "    \"NBR\": [\n",
    "        {\"split_ratio\": 0.02, \"ex_date\": \"2020-04-23\"}\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Define the function\n",
    "def adjust_target_price(target_price, report_date, ticker, stock_splits):\n",
    "    if pd.isna(target_price):\n",
    "        return None  # Handle NaN target prices\n",
    "    \n",
    "    #report_date = datetime.strptime(report_date, \"%Y-%m-%d\")\n",
    "    splits = stock_splits.get(ticker, [])\n",
    "    \n",
    "  \n",
    "\n",
    "    for split in splits:\n",
    "        split_date = datetime.strptime(split[\"ex_date\"], \"%Y-%m-%d\").date()\n",
    "        if split_date > report_date:\n",
    "            target_price /= split[\"split_ratio\"]\n",
    "    \n",
    "    return round(target_price,2)\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df_saved_reports[\"adjusted_target_price\"] = df_saved_reports.apply(\n",
    "    lambda row: adjust_target_price(\n",
    "        target_price=row[\"target_price\"],\n",
    "        report_date=row[\"date\"],\n",
    "        ticker=row[\"ticker\"],\n",
    "        stock_splits=stock_splits\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_saved_reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate performance of Target Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the adjusted_target_price is below the current price, we need to check if it was below the adjusted_target_price\n",
    "def classifcy_performance(df):\n",
    "    if df[\"adjusted_target_price\"] > df[\"start price\"]:\n",
    "        df[\"tp reached after 3 months\"] = df[\"adjusted_target_price\"] <= df[\"max price after 3 months\"]\n",
    "        df[\"tp reached after 6 months\"] = df[\"adjusted_target_price\"] <= df[\"max price after 6 months\"]\n",
    "        df[\"tp reached after 9 months\"] = df[\"adjusted_target_price\"] <= df[\"max price after 9 months\"]\n",
    "        df[\"tp reached after 12 months\"] = df[\"adjusted_target_price\"] <= df[\"max price after 12 months\"]\n",
    "    else:\n",
    "        df[\"tp reached after 3 months\"] = df[\"adjusted_target_price\"] >= df[\"min price after 3 months\"]\n",
    "        df[\"tp reached after 6 months\"] = df[\"adjusted_target_price\"] >= df[\"min price after 6 months\"]\n",
    "        df[\"tp reached after 9 months\"] = df[\"adjusted_target_price\"] >= df[\"min price after 9 months\"]\n",
    "        df[\"tp reached after 12 months\"] = df[\"adjusted_target_price\"] <= df[\"min price after 12 months\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "df_saved_reports = df_saved_reports.apply(classifcy_performance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saved_reports.to_csv(\"reports.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean/Filter Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saved_reports.to_csv(\"/Users/oskarroeske/Masterthesis/full_analysis/preprocessed_reports.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the cleaned list into separate rows\n",
    "df_exploded = df_saved_reports.explode('paragraphs').reset_index(drop=True)\n",
    "df_exploded = df_exploded[[\"document_id\",\"provider\",\"ticker\",\"date\",\"industry\",\"paragraphs\"]]\n",
    "df_exploded['paragraph_id'] = df_exploded.groupby('document_id').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "': $150.00 We raise our estimates for 3Q16 as we increase our estimates for Ad revenue going forward based on FBs increased number of advertisers using its platform, 4mm up from approximately 3mm in 3/16, and our belief that ad Entertainment & Internet growth will continue to realize robust performance for at least the next 12 to 18 months. We now expect 3Q16 revenue of $6.855B up 52% y/y, 5% above previous estimates, Operating Income of $2.74B up 88% y/y, 7% above previous estimates, Non-GAAP Operating Income of $3.775B up 57% y/y, 5% above previous estimates, and Non- GAAP EPS of $0.97 up 70% y/y, 5% above previous estimates. FB will report 3Q16 earnings on Wednesday, November 2, 2016 after the market closes and will host a call at 5 pm ET. The call in number is , ID . 3Q16 Advertising We maintain our Buy rating and $150 Target Price. revenue should reach approximately $6.663B up 55% y/y and 3Q16 Mobile. 5% above previous estimates. We expect mobile ad revenue to represent approximately 85% of FBs total ad revenue in 3Q16E above FBs 84% level in 2Q16, implying mobile revenue 3Q16 Payments of approximately $5.663B. and Other Fees should report revenue of about $192mm down 5% Raising Estimates for FY16. y/y and no change from previous estimates. We raise our estimates for FY16 as we expect ad growth to continue for the remainder of FY16 and into FY17. As a result, we now expect revenue of $27.04B up 51% y/y and 2% above previous estimates, and Non-GAAP Raising Estimates for FY17. EPS of $3.92 up 72% y/y and 2% above previous estimates. We raise our estimates for FY17 and now expect revenue of $36.557B up 35% y/y and 4% above previous estimates, and Non-GAAP Investment Thesis. EPS of $5.03 up 28% y/y and 8% above previous estimates. We are buyers of FB based on our belief that digital markets Stock Price Performance are winner take all markets and that FB is particularly well positioned owing to its always-registered environment with real names, its closed platform, global scale, ubiquitous distribution, and optionality of new revenue streams video, payments, commerce, etc on the core FB site as well as revenue upside potential from FBs other key apps such as Instagram WhatsApp, and FB Messenger.'"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"paragraphs\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn paragraphs into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.language import Language\n",
    "from spacy.pipeline import Sentencizer\n",
    "\n",
    "# Load spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add a customized sentence boundary detection component to spaCy\n",
    "@Language.component(\"custom_sentencizer\")\n",
    "def custom_sentencizer(doc):\n",
    "\n",
    "    for token in doc[:-1]:\n",
    "        # Always split at '!' or '?'\n",
    "        if token.text in [\"!\", \"?\"]:\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "\n",
    "        # Split at '.' only if not part of a number or abbreviation\n",
    "        if token.text == \".\":\n",
    "            next_token = token.nbor(1) if token.i + 1 < len(doc) else None\n",
    "            prev_token = token.nbor(-1) if token.i - 1 >= 0 else None\n",
    "            prev_prev_token = token.nbor(-2) if token.i - 2 >= 0 else None\n",
    "            \n",
    "            # Check if next token starts a title-case word\n",
    "            if next_token and next_token.is_title:\n",
    "                doc[token.i + 1].is_sent_start = True\n",
    "            \n",
    "            # Prevent splitting for abbreviations\n",
    "            if prev_token and prev_token.text.lower() in {\"mr\", \"ms\", \"dr\", \"etc\", \"e.g\", \"adj\", \"sr\"}:\n",
    "                doc[token.i + 1].is_sent_start = False\n",
    "            \n",
    "            # Prevent splitting within numbers (e.g., 3.14)\n",
    "            if prev_token and prev_token.like_num and next_token and next_token.like_num:\n",
    "                doc[token.i + 1].is_sent_start = False\n",
    "\n",
    "            # Prevent splitting if there are at least two uppercase words before the period\n",
    "            if (\n",
    "                prev_prev_token and prev_prev_token.text.isupper() and\n",
    "                prev_token and prev_token.text.isupper() and\n",
    "                next_token and next_token.is_lower\n",
    "            ):\n",
    "                doc[token.i + 1].is_sent_start = False\n",
    "\n",
    "    return doc\n",
    "# Add the custom sentencizer to the pipeline\n",
    "nlp.add_pipe(\"custom_sentencizer\", before=\"parser\")\n",
    "\n",
    "# Function to split paragraphs into sentences\n",
    "def split_into_sentences(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []  # Return an empty list for non-string values\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "result = []\n",
    "\n",
    "def check_sentence_validity(sentence):\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "    has_verb = False\n",
    "    has_subject = False\n",
    "\n",
    "    sentence = nlp(sentence)\n",
    "        \n",
    "    for token in sentence:\n",
    "        # Check for a verb\n",
    "        if token.pos_ in {\"VERB\", \"AUX\"}:\n",
    "            has_verb = True\n",
    "        # Check for a subject\n",
    "        if token.dep_ in {\"nsubj\", \"nsubjpass\"}:\n",
    "            has_subject = True\n",
    " \n",
    "    # If both a verb and a subject are found, the sentence is valid\n",
    "    if has_verb and has_subject:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Split each paragraph into sentences\n",
    "for _, row in df_exploded.iterrows():\n",
    "    doc_id = row['document_id']\n",
    "    paragraph_id = row['paragraph_id']\n",
    "    text = row['paragraphs']\n",
    "    sentences = split_into_sentences(text)\n",
    "    for sentence_id, sentence in enumerate(sentences, start=1):\n",
    "        is_valid_sentence = check_sentence_validity(sentence)\n",
    "        # Check if the sentence has more than 3 words\n",
    "        if len(sentence.split()) >= 5 and is_valid_sentence:\n",
    "            result.append({\n",
    "                'document_id': doc_id,\n",
    "                'paragraph_id': paragraph_id,\n",
    "                'sentence_id': sentence_id,\n",
    "                'sentence': sentence\n",
    "            })\n",
    "\n",
    "# Create a new DataFrame with the results\n",
    "df_preprocessed_sentences = pd.DataFrame(result)\n",
    "\n",
    "# Filter sentences from the table of contents -> caused issues before\n",
    "df_preprocessed_sentences = df_preprocessed_sentences[~df_preprocessed_sentences['sentence'].str.contains(r\"\\.{5,}\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>: $150.00 We raise our estimates for 3Q16 as w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>We now expect 3Q16 revenue of $6.855B up 52% y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>FB will report 3Q16 earnings on Wednesday, Nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The call in number is , ID .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Advertising We maintain our Buy rating and $15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34437</th>\n",
       "      <td>923</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Changes in that industrys presence or its reli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34438</th>\n",
       "      <td>923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>A looming threat for all web publishers relate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34439</th>\n",
       "      <td>923</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Rules could be established in the future which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34440</th>\n",
       "      <td>923</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Google has become so .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34441</th>\n",
       "      <td>923</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>large and so dominant in a number of sectors o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34435 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document_id  paragraph_id  sentence_id  \\\n",
       "0                1             1            1   \n",
       "1                1             1            2   \n",
       "2                1             1            3   \n",
       "3                1             1            4   \n",
       "4                1             1            6   \n",
       "...            ...           ...          ...   \n",
       "34437          923             4            6   \n",
       "34438          923             5            1   \n",
       "34439          923             5            2   \n",
       "34440          923             6            1   \n",
       "34441          923             6            2   \n",
       "\n",
       "                                                sentence  \n",
       "0      : $150.00 We raise our estimates for 3Q16 as w...  \n",
       "1      We now expect 3Q16 revenue of $6.855B up 52% y...  \n",
       "2      FB will report 3Q16 earnings on Wednesday, Nov...  \n",
       "3                           The call in number is , ID .  \n",
       "4      Advertising We maintain our Buy rating and $15...  \n",
       "...                                                  ...  \n",
       "34437  Changes in that industrys presence or its reli...  \n",
       "34438  A looming threat for all web publishers relate...  \n",
       "34439  Rules could be established in the future which...  \n",
       "34440                             Google has become so .  \n",
       "34441  large and so dominant in a number of sectors o...  \n",
       "\n",
       "[34435 rows x 4 columns]"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_sentences.to_csv(\"/Users/oskarroeske/Masterthesis/full_analysis/preprocessed_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate sentences back into paragraphs\n",
    "df_preprocessed_paragraphs = (\n",
    "    df_preprocessed_sentences\n",
    "    .groupby(['document_id','paragraph_id'])  # Group by paragraph_id\n",
    "    .agg({'sentence': ' '.join})  # Concatenate sentences within each group\n",
    "    .reset_index()  # Reset index to keep paragraph_id as a column\n",
    ")\n",
    "\n",
    "# Rename the column to 'paragraph' for clarity\n",
    "df_preprocessed_paragraphs.rename(columns={'sentence': 'paragraph'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>: $150.00 We raise our estimates for 3Q16 as w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Our $150 target price embeds a 10-year OIBDA g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>FB is the largest social network, with 1.65B u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Risks to our thesis and target price include a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>FB reported relatively strong 2Q resultsrevenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>923</td>\n",
       "      <td>2</td>\n",
       "      <td>Investors will need to consider the following ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>923</td>\n",
       "      <td>3</td>\n",
       "      <td>Much of online advertising is highly competiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>923</td>\n",
       "      <td>4</td>\n",
       "      <td>SMEs have been the core . We believe they have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>923</td>\n",
       "      <td>5</td>\n",
       "      <td>A looming threat for all web publishers relate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10570</th>\n",
       "      <td>923</td>\n",
       "      <td>6</td>\n",
       "      <td>Google has become so . large and so dominant i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document_id  paragraph_id  \\\n",
       "0                1             1   \n",
       "1                1             2   \n",
       "2                1             3   \n",
       "3                1             4   \n",
       "4                2             1   \n",
       "...            ...           ...   \n",
       "10566          923             2   \n",
       "10567          923             3   \n",
       "10568          923             4   \n",
       "10569          923             5   \n",
       "10570          923             6   \n",
       "\n",
       "                                               paragraph  \n",
       "0      : $150.00 We raise our estimates for 3Q16 as w...  \n",
       "1      Our $150 target price embeds a 10-year OIBDA g...  \n",
       "2      FB is the largest social network, with 1.65B u...  \n",
       "3      Risks to our thesis and target price include a...  \n",
       "4      FB reported relatively strong 2Q resultsrevenu...  \n",
       "...                                                  ...  \n",
       "10566  Investors will need to consider the following ...  \n",
       "10567  Much of online advertising is highly competiti...  \n",
       "10568  SMEs have been the core . We believe they have...  \n",
       "10569  A looming threat for all web publishers relate...  \n",
       "10570  Google has become so . large and so dominant i...  \n",
       "\n",
       "[10571 rows x 3 columns]"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_id\n",
       "677    135\n",
       "192    108\n",
       "660    106\n",
       "560    101\n",
       "289     99\n",
       "      ... \n",
       "261      1\n",
       "217      1\n",
       "587      1\n",
       "725      1\n",
       "534      1\n",
       "Name: count, Length: 922, dtype: int64"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed_paragraphs.value_counts(\"document_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_paragraphs.to_csv(\"/Users/oskarroeske/Masterthesis/full_analysis/preprocessed_paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_paragraphs['token_count'] = df_preprocessed_paragraphs['paragraph'].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum tokens in the column: 1044\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum token count\n",
    "\n",
    "max_tokens = df_preprocessed_paragraphs['token_count'].max()\n",
    "print(f\"Maximum tokens in the column: {max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles for token counts:\n",
      "0.25      44.0\n",
      "0.50      83.0\n",
      "0.75     141.0\n",
      "0.90     222.0\n",
      "0.95     300.0\n",
      "0.97     370.0\n",
      "0.99     539.0\n",
      "1.00    1044.0\n",
      "Name: token_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate df_preprocessed_paragraphs\n",
    "percentiles = df_preprocessed_paragraphs['token_count'].quantile([0.25, 0.5, 0.75, 0.9,0.95,0.97,0.99,1.0])\n",
    "\n",
    "# Display percentiles\n",
    "print(\"Percentiles for token counts:\")\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
